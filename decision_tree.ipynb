{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree for the human dataset\n",
    "## 1. Data Preprocessing\n",
    "we're going to train a decicison tree model for the dataset and test how good it works.\n",
    "We will use the scikit-learn library for its powerful funtionality. First import the packages and read the prepocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data_train = pd.read_csv('data_train.csv')\n",
    "data_test = pd.read_csv('data_test.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the sklearn.tree library cannot deal with attributes in strings, so we first have to convert all the string attributes to integers using LabelEncoder(). 'Education' doesn't need to be converted because it was already converted to interger in the original data as a column called 'educational_num'. Each string value of 'education' corrsponds to a unique interger in 'educational_num'. Repeast this process in both training dataset and testing dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a categorical variable to numerical values\n",
    "encoder = LabelEncoder()\n",
    "data_train['workclass'] = encoder.fit_transform(data_train['workclass'])\n",
    "data_train['marital-status'] = encoder.fit_transform(data_train['marital-status'])\n",
    "data_train['occupation'] = encoder.fit_transform(data_train['occupation'])\n",
    "data_train['relationship'] = encoder.fit_transform(data_train['relationship'])\n",
    "data_train['race'] = encoder.fit_transform(data_train['race'])\n",
    "data_train['gender'] = encoder.fit_transform(data_train['gender'])\n",
    "data_train['native-country'] = encoder.fit_transform(data_train['native-country'])\n",
    "data_test['workclass'] = encoder.fit_transform(data_test['workclass'])\n",
    "data_test['marital-status'] = encoder.fit_transform(data_test['marital-status'])\n",
    "data_test['occupation'] = encoder.fit_transform(data_test['occupation'])\n",
    "data_test['relationship'] = encoder.fit_transform(data_test['relationship'])\n",
    "data_test['race'] = encoder.fit_transform(data_test['race'])\n",
    "data_test['gender'] = encoder.fit_transform(data_test['gender'])\n",
    "data_test['native-country'] = encoder.fit_transform(data_test['native-country'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using 13 colums as the X, so create X_train and X_test using all these columns. Set y_train and y_test using the 'income' column. As Decision trees are not sensitive to the scale of the features, standard scaling is skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  workclass  fnlwgt  educational_num  marital-status  occupation  \\\n",
      "0       39          6   77516               13               4           0   \n",
      "1       50          5   83311               13               2           3   \n",
      "2       38          3  215646                9               0           5   \n",
      "3       53          3  234721                7               2           5   \n",
      "4       28          3  338409               13               2           9   \n",
      "...    ...        ...     ...              ...             ...         ...   \n",
      "32556   27          3  257302               12               2          12   \n",
      "32557   40          3  154374                9               2           6   \n",
      "32558   58          3  151910                9               6           0   \n",
      "32559   22          3  201490                9               4           0   \n",
      "32560   52          4  287927                9               2           3   \n",
      "\n",
      "       relationship  race  gender  capital-gain  capital-loss  hours-per-week  \\\n",
      "0                 1     4       1          2174             0              40   \n",
      "1                 0     4       1             0             0              13   \n",
      "2                 1     4       1             0             0              40   \n",
      "3                 0     2       1             0             0              40   \n",
      "4                 5     2       0             0             0              40   \n",
      "...             ...   ...     ...           ...           ...             ...   \n",
      "32556             5     4       0             0             0              38   \n",
      "32557             0     4       1             0             0              40   \n",
      "32558             4     4       0             0             0              40   \n",
      "32559             3     4       1             0             0              20   \n",
      "32560             5     4       0         15024             0              40   \n",
      "\n",
      "       native-country  \n",
      "0                  38  \n",
      "1                  38  \n",
      "2                  38  \n",
      "3                  38  \n",
      "4                   4  \n",
      "...               ...  \n",
      "32556              38  \n",
      "32557              38  \n",
      "32558              38  \n",
      "32559              38  \n",
      "32560              38  \n",
      "\n",
      "[32561 rows x 13 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "32556    0\n",
      "32557    1\n",
      "32558    0\n",
      "32559    0\n",
      "32560    1\n",
      "Name: income, Length: 32561, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set x_train and X_test to contain all the input columns of the DataFrame\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "x_train = data_train[feature_names]\n",
    "x_test = data_test[feature_names]\n",
    "\n",
    "# Set y_train and y_test to contain the target variable of the DataFrame\n",
    "y_train = data_train['income']\n",
    "y_test = data_test['income']\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. get a prelimenery result using default settings of sklearn.tree\n",
    "feed the data into DecisionTreeClassifier() and get the result. The accuracy is 0.81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87     12435\n",
      "           1       0.59      0.61      0.60      3846\n",
      "\n",
      "    accuracy                           0.81     16281\n",
      "   macro avg       0.73      0.74      0.74     16281\n",
      "weighted avg       0.81      0.81      0.81     16281\n",
      "\n",
      "0.7388844769713587\n",
      "[[10820  1615]\n",
      " [ 1509  2337]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "#Summarize Result\n",
    "#precision,recall,f1-score,support, accuracy, macro avg, weighted avg\n",
    "print(classification_report(y_test,y_pred))\n",
    "#ROC score\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "#confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning\n",
    "### 3.1 Preparation for tuning\n",
    "Above was just the first attempt without validation. The tree we obtain here is too complex. In order to avoid overfitting on training data, validation is necessary. We will start with the most basic hyperparameter, the map depth of the tree. To do so, we first import more packages for the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing validation, we have to split the original training set into the actual training set and a new validation set, while keeping the test set unseen still. So we rename the data directly read from the csv file to data_train_val for clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val = pd.read_csv('data_train.csv')\n",
    "data_train_val['workclass'] = encoder.fit_transform(data_train_val['workclass'])\n",
    "data_train_val['marital-status'] = encoder.fit_transform(data_train_val['marital-status'])\n",
    "data_train_val['occupation'] = encoder.fit_transform(data_train_val['occupation'])\n",
    "data_train_val['relationship'] = encoder.fit_transform(data_train_val['relationship'])\n",
    "data_train_val['race'] = encoder.fit_transform(data_train_val['race'])\n",
    "data_train_val['gender'] = encoder.fit_transform(data_train_val['gender'])\n",
    "data_train_val['native-country'] = encoder.fit_transform(data_train_val['native-country'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Single search for the max depth of the tree\n",
    "split the training data and validation data using 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into real training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_train_val[feature_names], data_train_val['income'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over values of max_depth to find the one that makes the highest cross-validation score. There are several metrics for evaluating a decision tree model, such as accuracy, precision, recall and AUC. They can be useful depending on the specific problem. Since the data is quite imbalanced, we believe the AUC (Area Under the ROC Curve) should be the most useful one but we will list all the other metrics when comparing the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunyu\\anaconda3\\envs\\geospatial\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sunyu\\anaconda3\\envs\\geospatial\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sunyu\\anaconda3\\envs\\geospatial\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sunyu\\anaconda3\\envs\\geospatial\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sunyu\\anaconda3\\envs\\geospatial\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 8\n",
      "Accuracy: 0.851620158377885\n",
      "Precision: 0.7596666965590482\n",
      "Recall: 0.5661881977671451\n",
      "AUC: 0.8968178664470596\n",
      "|    |   fit_time |   score_time |   test_accuracy |   test_precision |   test_recall |   test_roc_auc |\n",
      "|---:|-----------:|-------------:|----------------:|-----------------:|--------------:|---------------:|\n",
      "|  0 |  0.0757947 |    0.0189512 |        0.841651 |         0.705263 |      0.587719 |       0.863921 |\n",
      "|  1 |  0.101755  |    0.0189226 |        0.850672 |         0.713262 |      0.634769 |       0.869088 |\n",
      "|  2 |  0.0867417 |    0.0169792 |        0.853935 |         0.739553 |      0.606858 |       0.871872 |\n",
      "|  3 |  0.0937223 |    0.014962  |        0.853715 |         0.732075 |      0.61882  |       0.877103 |\n",
      "|  4 |  0.0927556 |    0.0179484 |        0.85621  |         0.74209  |      0.617225 |       0.858752 |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define range of values for maximum depth of tree\n",
    "max_depth_values = range(1, len(feature_names))\n",
    "\n",
    "# Create arrays to store the evaluation metrics for each max_depth value\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "\n",
    "    # Create a new DecisionTreeClassifier with the current max_depth value\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "\n",
    "    # Use cross_validate to calculate the evaluation metrics with 5-fold cross-validation\n",
    "    cv_results = cross_validate(clf, X_train, y_train, cv=5, scoring=['accuracy', 'precision', 'recall', 'roc_auc'])\n",
    "\n",
    "    # Store the mean evaluation metrics for the current max_depth value\n",
    "    accuracy_scores.append(np.mean(cv_results['test_accuracy']))\n",
    "    precision_scores.append(np.mean(cv_results['test_precision']))\n",
    "    recall_scores.append(np.mean(cv_results['test_recall']))\n",
    "    auc_scores.append(np.mean(cv_results['test_roc_auc']))\n",
    "\n",
    "# Find the index of the max AUC score\n",
    "best_index = np.argmax(auc_scores)\n",
    "\n",
    "# Find the best max_depth value based on the index\n",
    "best_max_depth = max_depth_values[best_index]\n",
    "\n",
    "# Print the best max_depth value and the corresponding evaluation metrics\n",
    "print(\"Best max_depth:\", best_max_depth)\n",
    "print(\"Accuracy:\", accuracy_scores[best_index])\n",
    "print(\"Precision:\", precision_scores[best_index])\n",
    "print(\"Recall:\", recall_scores[best_index])\n",
    "print(\"AUC:\", auc_scores[best_index])\n",
    "\n",
    "# Covert the array to a Dataframe\n",
    "df_cv_results = pd.DataFrame(cv_results, columns=['fit_time', 'score_time', 'test_accuracy','test_precision','test_recall','test_roc_auc'])\n",
    "print(df_cv_results.to_markdown())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the maximum depth 8 is found to be the best maximum of depth."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Further validation: grid search of hyperparameters \n",
    "Now that we have made our first step into validation, the question becomes, is there a need to validate more hyperparameters to further improve the tree? It's very obvious that the more parameters we put into validation, the higher validation score we will get, but this doesn't necessarily mean the model becomes better because we may end up overfitting to the validation set. There are several more parameters to adjust, so we start with the pair maximum depth and min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 8, 'min_samples_leaf': 1}\n",
      "Best cross-validation score: 0.8549185507269341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 8]\n",
    "}\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the data\n",
    "grid_search = GridSearchCV(tree, param_grid, cv=5)\n",
    "grid_search.fit(data_train_val[feature_names], data_train_val['income'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the best combination of hyperparameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best mean cross-validation score\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the hyperparameters obtained to run the test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8546772311283091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decision_tree.png'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tree using the test set\n",
    "x_train = data_train_val[feature_names]\n",
    "x_test = data_test[feature_names]\n",
    "\n",
    "# Set y_train and y_test to contain the target variable of the DataFrame\n",
    "y_train = data_train_val['income']\n",
    "y_test = data_test['income']\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=grid_search.best_params_['max_depth'], min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Visualize the decision tree\n",
    "export_graphviz(clf, out_file=\"tree.dot\", feature_names=feature_names, filled=True,\n",
    "                rounded=True, special_characters=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graph = Source(dot_graph)\n",
    "graph.format = \"png\"\n",
    "graph.render(\"decision_tree\", view=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
