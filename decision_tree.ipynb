{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree for the human dataset\n",
    "we're going to train a decicison tree model for the dataset and test how good it works.\n",
    "We will use the scikit-learn library for its powerful funtionality. First import the packages and read the prepocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data_train = pd.read_csv('data_train.csv')\n",
    "data_test = pd.read_csv('data_test.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the sklearn.tree library cannot deal with attributes in strings, so we first have to convert all the string attributes to integers using LabelEncoder(). 'Education' doesn't need to be converted because it was already converted to interger in the original data as a column called 'educational_num'. Each string value of 'education' corrsponds to a unique interger in 'educational_num'. Repeast this process in both training dataset and testing dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a categorical variable to numerical values\n",
    "encoder = LabelEncoder()\n",
    "data_train['workclass'] = encoder.fit_transform(data_train['workclass'])\n",
    "data_train['marital-status'] = encoder.fit_transform(data_train['marital-status'])\n",
    "data_train['occupation'] = encoder.fit_transform(data_train['occupation'])\n",
    "data_train['relationship'] = encoder.fit_transform(data_train['relationship'])\n",
    "data_train['race'] = encoder.fit_transform(data_train['race'])\n",
    "data_train['gender'] = encoder.fit_transform(data_train['gender'])\n",
    "data_train['native-country'] = encoder.fit_transform(data_train['native-country'])\n",
    "data_test['workclass'] = encoder.fit_transform(data_test['workclass'])\n",
    "data_test['marital-status'] = encoder.fit_transform(data_test['marital-status'])\n",
    "data_test['occupation'] = encoder.fit_transform(data_test['occupation'])\n",
    "data_test['relationship'] = encoder.fit_transform(data_test['relationship'])\n",
    "data_test['race'] = encoder.fit_transform(data_test['race'])\n",
    "data_test['gender'] = encoder.fit_transform(data_test['gender'])\n",
    "data_test['native-country'] = encoder.fit_transform(data_test['native-country'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using 13 colums as the X, so create X_train and X_test using all these columns. Set y_train and y_test using the 'income' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x_train and X_test to contain all the input columns of the DataFrame\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "x_train = data_train[feature_names]\n",
    "x_test = data_test[feature_names]\n",
    "\n",
    "# Set y_train and y_test to contain the target variable of the DataFrame\n",
    "y_train = data_train['income']\n",
    "y_test = data_test['income']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feed the data into DecisionTreeClassifier() and get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808549843375714\n"
     ]
    }
   ],
   "source": [
    "# Initialize a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just the first attempt without validation. The tree we obtain here is too complex. In order to avoid overfitting on training data, validation is necessary. We will start with the most basic hyperparameter, the map depth of the tree. To do so, we first import more packages for the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing validation, we have to split the original training set into the actual training set and a new validation set, while keeping the test set unseen still. So we rename the data directly read from the csv file to data_train_val for clarification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val = pd.read_csv('data_train.csv')\n",
    "data_train_val['workclass'] = encoder.fit_transform(data_train_val['workclass'])\n",
    "data_train_val['marital-status'] = encoder.fit_transform(data_train_val['marital-status'])\n",
    "data_train_val['occupation'] = encoder.fit_transform(data_train_val['occupation'])\n",
    "data_train_val['relationship'] = encoder.fit_transform(data_train_val['relationship'])\n",
    "data_train_val['race'] = encoder.fit_transform(data_train_val['race'])\n",
    "data_train_val['gender'] = encoder.fit_transform(data_train_val['gender'])\n",
    "data_train_val['native-country'] = encoder.fit_transform(data_train_val['native-country'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the training data and validation data using 5-fold. Print out the best maximum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into real training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_train_val[feature_names], data_train_val['income'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define range of values for maximum depth of tree\n",
    "max_depth_values = range(1, len(feature_names))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over values of max_depth to find the one that makes the highest cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Loop over values of max_depth and calculate cross-validation score for each\n",
    "cv_scores = []\n",
    "for max_depth in max_depth_values:\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Choose value of max_depth that gives best cross-validation score\n",
    "best_max_depth = max_depth_values[np.argmax(cv_scores)]\n",
    "\n",
    "print(best_max_depth)\n",
    "\n",
    "# Train final model using best value of max_depth\n",
    "final_clf = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "final_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance on validation set\n",
    "val_score = final_clf.score(X_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the best_max_depth obtained, make another fitting and check the predition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8568269762299613\n"
     ]
    }
   ],
   "source": [
    "# Test the tree using the test set\n",
    "x_train = data_train_val[feature_names]\n",
    "x_test = data_test[feature_names]\n",
    "\n",
    "# Set y_train and y_test to contain the target variable of the DataFrame\n",
    "y_train = data_train_val['income']\n",
    "y_test = data_test['income']\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=best_max_depth)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the tree, the tree should look like this '![Alt text](decision_tree1.png)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree.png'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the decision tree\n",
    "export_graphviz(clf, out_file=\"tree.dot\", feature_names=feature_names, filled=True,\n",
    "                rounded=True, special_characters=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graph = Source(dot_graph)\n",
    "graph.format = \"png\"\n",
    "graph.render(\"decision_tree\", view=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have significantly shrinked the tree the final accuracy on the test set has improved, which indicates the cross-validation has worked out. Now the question is, is there a need to validate more hyperparameters to further improve the tree? There are several more parameters to adjust, so we start with the pair maximum depth and min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 8, 'min_samples_leaf': 1}\n",
      "Best cross-validation score: 0.8550413961342105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'min_samples_leaf': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the data\n",
    "grid_search = GridSearchCV(tree, param_grid, cv=5)\n",
    "grid_search.fit(data_train_val[feature_names], data_train_val['income'])\n",
    "\n",
    "# Print the best combination of hyperparameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best mean cross-validation score\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the hyperparameters obtained to run the test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8544929672624532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decision_tree.png'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the tree using the test set\n",
    "x_train = data_train_val[feature_names]\n",
    "x_test = data_test[feature_names]\n",
    "\n",
    "# Set y_train and y_test to contain the target variable of the DataFrame\n",
    "y_train = data_train_val['income']\n",
    "y_test = data_test['income']\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=grid_search.best_params_['max_depth'], min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Visualize the decision tree\n",
    "export_graphviz(clf, out_file=\"tree.dot\", feature_names=feature_names, filled=True,\n",
    "                rounded=True, special_characters=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graph = Source(dot_graph)\n",
    "graph.format = \"png\"\n",
    "graph.render(\"decision_tree\", view=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
