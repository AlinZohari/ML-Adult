{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare test data for the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data_test['workclass'] = encoder.fit_transform(data_test['workclass'])\n",
    "data_test['marital-status'] = encoder.fit_transform(\n",
    "    data_test['marital-status'])\n",
    "data_test['occupation'] = encoder.fit_transform(data_test['occupation'])\n",
    "data_test['relationship'] = encoder.fit_transform(data_test['relationship'])\n",
    "data_test['race'] = encoder.fit_transform(data_test['race'])\n",
    "data_test['gender'] = encoder.fit_transform(data_test['gender'])\n",
    "data_test['native-country'] = encoder.fit_transform(\n",
    "    data_test['native-country'])\n",
    "\n",
    "# Preprocessed test set for decision tree\n",
    "x_test_tree = data_test[feature_names]\n",
    "y_test_tree = data_test['income']\n",
    "\n",
    "# Preprocessed test set\n",
    "# print(x_test_tree)\n",
    "# print(y_test_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare test data for the k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "# transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_test\n",
    "le = LabelEncoder()\n",
    "test_knn = []\n",
    "for col in cat_columns:\n",
    "    data_test[col] = le.fit_transform(data_test[col])\n",
    "\n",
    "# Split the test set\n",
    "x_test_knn = data_test.drop(columns =['income'])\n",
    "y_test_knn = data_test['income']\n",
    "\n",
    "# Print the first 5 rows of the transformed dataset\n",
    "# print(x_test_knn.head())\n",
    "# print(y_test_knn.head())\n",
    "\n",
    "#Standard Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_test_knn = preprocessing.StandardScaler().fit(x_test_knn).transform(x_test_knn.astype(float))\n",
    "# print(x_test_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prepare test data for the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv', header=0)\n",
    "\n",
    "# feature transformation\n",
    "for col in data_test:\n",
    "    if data_test[col].dtype == 'object':\n",
    "        data_test[col] = encoder.fit_transform(data_test[col].astype(str))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "for col in data_test.columns:\n",
    "    data_test[col] = scaler.fit_transform(data_test[[col]])\n",
    "\n",
    "x_test_nn = data_test.iloc[:, :-1]\n",
    "y_test_nn = data_test.iloc[:, -1]\n",
    "# print(x_test_nn)\n",
    "# print(y_test_nn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare test for the Bayesian learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the testing data\n",
    "import pandas as pd\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "data_test = data_test.reset_index()\n",
    "xs_test = data_test.drop(['income'], axis=1)\n",
    "ys_test = data_test['income']\n",
    "\n",
    "#Store all the categorical features\n",
    "categorical = [var for var in xs_test.columns if xs_test[var].dtype=='O']\n",
    "# print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "# print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "#Store all the numerical features\n",
    "numerical = [var for var in xs_test.columns if xs_test[var].dtype!='O']\n",
    "# print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "# print('The numerical variables are :\\n\\n', numerical)\n",
    "\n",
    "# Discretization the numerical features##\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#Age\n",
    "age_t = xs_test['age']\n",
    "age_t=age_t.values.reshape(-1,1)\n",
    "age_trans_t = kbins.fit_transform(age_t)\n",
    "\n",
    "#Final weight\n",
    "fw_t = xs_test['fnlwgt']\n",
    "fw_t=fw_t.values.reshape(-1,1)\n",
    "fw_trans_t = kbins.fit_transform(fw_t)\n",
    "\n",
    "#educational_num\n",
    "edunum_t = xs_test['educational_num']\n",
    "edunum_t=edunum_t.values.reshape(-1,1)\n",
    "edunum_trans_t = kbins.fit_transform(edunum_t)\n",
    "\n",
    "#capital gain\n",
    "cg_t = xs_test['capital-gain']\n",
    "cg_t=cg_t.values.reshape(-1,1)\n",
    "cg_trans_t = kbins.fit_transform(cg_t)\n",
    "\n",
    "#capital loss\n",
    "cl_t = xs_test['capital-loss']\n",
    "cl_t=cl_t.values.reshape(-1,1)\n",
    "cl_trans_t = kbins.fit_transform(cl_t)\n",
    "\n",
    "#hours-per-week\n",
    "hours_t = xs_test['hours-per-week']\n",
    "hours_t=hours_t.values.reshape(-1,1)\n",
    "hours_trans_t = kbins.fit_transform(hours_t)\n",
    "\n",
    "age_t=pd.DataFrame(age_trans_t,columns =['age'])\n",
    "fw_t=pd.DataFrame(fw_trans_t,columns =['fnlwgt'])\n",
    "edunum_t=pd.DataFrame(edunum_trans_t,columns =['educational-num'])\n",
    "cg_t=pd.DataFrame(cg_trans_t,columns =['capital-gain'])\n",
    "cl_t=pd.DataFrame(cl_trans_t,columns =['capital-loss'])\n",
    "hours_t=pd.DataFrame(hours_trans_t,columns =['hours-per-week'])\n",
    "\n",
    "\n",
    "numerical_trans_t = pd.concat([age_t,fw_t,edunum_t,cg_t,cl_t,hours_t],axis=1)\n",
    "\n",
    "xs_bnb_test = pd.concat([xs_test[categorical],numerical_trans_t],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# import the trained encoder_bnb\n",
    "import pickle\n",
    "with open(\"output/Bayes_Learning/encoder_bnb.pkl\", \"rb\") as f:\n",
    "    encoder_bnb = pickle.load(f)\n",
    "\n",
    "#Encode the unseen test data\n",
    "# xs_bnb_test = encoder_bnb.transform(xs_bnb_test)\n",
    "# ys_bnb_test = ys_test\n",
    "\n",
    "x_test_nb = encoder_bnb.transform(xs_bnb_test)\n",
    "y_test_nb = ys_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
