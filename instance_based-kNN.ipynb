{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance-Based Learning: K-Nearest Neighbours(kNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_train.csv')\n",
    "test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transformation of the categorical attrbutes to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_train\n",
    "le = LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_test\n",
    "le = LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the transformed dataset\n",
    "#print(train.head())\n",
    "#print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train\n",
    "x_train_trans = train.drop(columns = ['income'])\n",
    "y_train = train['income']\n",
    "\n",
    "#test\n",
    "x_test_trans = test.drop(columns =['income'])\n",
    "y_test = test['income']\n",
    "\n",
    "#print(x_train_trans)\n",
    "#print(y_train_trans)\n",
    "#print(x_test_trans)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Scaling\n",
    "\n",
    "\n",
    "StandardScaler is being used to standardize the data by removing the mean and scaling to unit variance. This is common preprocessing step in machine learning to ensure that all features are on the same scale, which can improve the performance and accuracy of many algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train = preprocessing.StandardScaler().fit(x_train_trans).transform(x_train_trans.astype(float))\n",
    "#print(x_train)\n",
    "\n",
    "x_test = preprocessing.StandardScaler().fit(x_test_trans).transform(x_test_trans.astype(float))\n",
    "#print(x_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using default kNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a validation of performance and confusion matrix for doing default kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "#base model\n",
    "default_knn = KNeighborsClassifier()\n",
    "default_knn.fit(x_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred=default_knn.predict(x_test)\n",
    "\n",
    "\n",
    "#Summarize Result\n",
    "#precision,recall,f1-score,support, accuracy, macro avg, weighted avg\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#ROC score\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC_AUC score: ', auc)\n",
    "\n",
    "#plotting roc curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "#Confusion matrix\n",
    "cm = (confusion_matrix(y_test,y_pred,))\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "#confusion matrix plot\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for K-neighbours, Weight and Distance Metric and validating its performance using accuracy, precision, recall and F1-score\n",
    "\n",
    "This will be done by making a ranking of validation\n",
    "\n",
    "-GridSearchCV \n",
    "with a sklearn.model_selection.GridSearchCV\n",
    "\n",
    "-Training and Validation Split 10% \n",
    "    -goals on validation: how robust the validation - doesnt have much variance when you the validation again - (find the robust percentage-is it really 10%)\n",
    "\n",
    "-Find whether training/validation split and k-folds is the best for kNN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method: K-folds Cross Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-folds Cross Validation is used as it uses all the data for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "# Creating a parameter of the grid\n",
    "param_grid = [{\n",
    "    'n_neighbors': list(range(1, 30, 2)),\n",
    "    'metric': ['euclidean', 'manhattan', 'cosine', 'minkowski'],\n",
    "    'weights':['uniform','distance'],\n",
    "    #'algorithm':['auto','ball_tree','kd-tree','brute'],\n",
    "    'leaf_size' : list(range(1,50, 5))\n",
    "}]\n",
    "#is this how you put the hyperparameter range?\n",
    "\n",
    "#making a score ranking\n",
    "from sklearn.metrics import  roc_auc_score, make_scorer\n",
    "ROC_AUC = make_scorer(roc_auc_score, pos_label = 1, average = 'binary')\n",
    "\n",
    "# Grid search model\n",
    "knn_grid = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(estimator = knn_grid, param_grid = param_grid, cv =5, scoring = 'ROC_AUC')\n",
    "#cv is the folds\n",
    "#go back and play around with this GridSearchCV parameter\n",
    "#from youtube: grid_search = GridSearchCV(estimator=knn,param_grid=knn_param, n_jobs=1, cv=cv, scoring=\"accuracy\", error_score=0)\n",
    "#from pratibha: grid_search = GridSearchCV(estimator = knn_clf, param_grid = param_grid,cv = n_folds, verbose = 2, scoring = f1, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is divided into k of 5 of equal parts (folds), and the model is trained and validated k times. \n",
    "\n",
    "-1200 candidates is the probablity of the combination\n",
    "-6000 fits are 1200 candidate x the k-folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best scorer and hyperparameter to achieve this score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best scorer\n",
    "print('Best scorer: ', grid_search.best_score_)\n",
    "\n",
    "#Finding the hyperparameter to achieve this score\n",
    "print(\"The list of hyperparmeter in order to achieve this best score: \", grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model with the best Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will inserting the cest hyperparameters that been found when grid search is done\n",
    "best_model = KNeighborsClassifier(n_neighbors=15, weights='uniform', leaf_size= 25, metric=\"manhattan\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(x_train,y_train)\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "#accuracy = best_model.score(x_train, y_train)\n",
    "#print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a validation of performance and confusion matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation and Confusion Matrix\n",
    "\n",
    "The best model with the tuned hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize Result\n",
    "#precision,recall,f1-score,support, accuracy, macro avg, weighted avg\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#ROC score\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC_AUC score: ', auc)\n",
    "#plotting roc curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "#Confusion matrix\n",
    "cm = (confusion_matrix(y_test,y_pred,))\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "#confusion matrix plot\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "#Print the best hyperparameter tuned for the best model again\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can check if the accuracy had improve between the default_knn and when the hyperparameter is tuned for the best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, 'kNN.pkl', compress=9)\n",
    "\n",
    "#what is compress=9, do we need that"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
