{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance-Based Learning: K-Nearest Neighbours(kNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#scikit-learn library - not complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_train.csv')\n",
    "test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data transformation of the categorical attrbutes to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_train\n",
    "le = LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_test\n",
    "le = LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the transformed dataset\n",
    "#print(train.head())\n",
    "#print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train\n",
    "x_train_trans = train.drop(columns = ['income'])\n",
    "y_train = train['income']\n",
    "\n",
    "#test\n",
    "x_test_trans = test.drop(columns =['income'])\n",
    "y_test = test['income']\n",
    "\n",
    "print(x_train_trans)\n",
    "#print(y_train_trans)\n",
    "#print(x_test_trans)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Scaling\n",
    "\n",
    "\n",
    "StandardScaler is being used to standardize the data by removing the mean and scaling to unit variance. This is commn preprocessing step in machine learning to ensure that all features are on the same scale, which can improve the performance and accuracy of many algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train = preprocessing.StandardScaler().fit(x_train_trans).transform(x_train_trans.astype(float))\n",
    "#print(x_train)\n",
    "\n",
    "x_test = preprocessing.StandardScaler().fit(x_test_trans).transform(x_test_trans.astype(float))\n",
    "print(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using default kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "default_knn = KNeighborsClassifier()\n",
    "default_knn.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_default = default_knn.predict(x_test)\n",
    "\n",
    "#there are a ValueError: Input X contains NaN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(default_knn, x_test, y_test)\n",
    "#plot_confusion_matrix is a library in sklearn.metrics\n",
    "plt.show()\n",
    "\n",
    "#Error: confusion_matrix() takes 2 positional arguments but 3 were given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_default))\n",
    "#needed from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for K-neighbours, Weight and Distance Metric and validating its performance using accuracy, precision, recall and F1-score\n",
    "\n",
    "This will be done by making a ranking of validation\n",
    "\n",
    "-GridSearchCV \n",
    "with a sklearn.model_selection.GridSearchCV\n",
    "\n",
    "-Training and Validation Split 10% \n",
    "    -goals on validation: how robust the validation - doesnt have much variance when you the validation again - (find the robust percentage-is it really 10%)\n",
    "\n",
    "-Find whether training/validation split and k-folds is the best for kNN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Method: K-folds Cross Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-folds Cross Validation is used as it uses all the data for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#creating a grid\n",
    "param_grid = [{\n",
    "    'weights':[\"uniform\",\"distance\"],\n",
    "    'n_neighbors': list(range(10, 20, 5)),\n",
    "    'metric': ['euclidean', 'manhattan', 'cosine'],\n",
    "    'leaf_size' : list(range(25,50, 5))\n",
    "}]\n",
    "\n",
    "n_folds = 5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is divided into k 5 of equal parts (folds), and the model is trained and validated k times. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model with the best Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix of the test datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(tuned_model, 'kNN.pkl', compress=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
