{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据集文件\n",
    "df = pd.read_csv('data_train.csv', header=0)\n",
    "\n",
    "# print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 统计正负样本数量和比例\n",
    "# : 表示选择所有行，-1 表示选择最后一列\n",
    "count = df.iloc[:,-1].value_counts()\n",
    "\n",
    "count.plot(kind='pie', labels=['Negative', 'Positive'], autopct='%1.1f%%', shadow=True)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制各个特征的直方图\n",
    "for feature in df.columns:\n",
    "    if feature == 'income':\n",
    "        continue\n",
    "    plt.hist(df[df['income'] == 0][feature], bins=20, alpha=0.5, label='Negative')\n",
    "    plt.hist(df[df['income'] == 1][feature], bins=20,alpha=0.5, label='Positive')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(feature)\n",
    "    plt.xticks(rotation=90, fontsize=8)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# 计算相关系数\n",
    "corr = df.corr()\n",
    "\n",
    "# 绘制热力图\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 创建 LabelEncoder 对象\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# 对 X_train 中的每一列进行 Label Encoding\n",
    "for col in df:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = encoder.fit_transform(df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 创建MinMaxScaler对象\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 对fnlwgt列进行特征缩放\n",
    "df['fnlwgt'] = scaler.fit_transform(df[['fnlwgt']])*100\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集dataset前80%作为训练数据集，后20%为检验数据集\n",
    "split_idx = int(len(df) * 0.8)\n",
    "\n",
    "df_train = df[:split_idx]\n",
    "df_valid = df[split_idx:]\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = df_train.iloc[:, :-1]\n",
    "y = df_train.iloc[:, -1]\n",
    "\n",
    "\n",
    "# 实例化 PCA 模型，设置降维后的维度为 2\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# 使用 PCA 模型对数据集进行降维\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# 将降维后的数据集和目标变量 y 合并为一个新的数据集\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=['PCA1', 'PCA2'])\n",
    "df_pca['target'] = y\n",
    "\n",
    "print(df_pca)\n",
    "\n",
    "# 绘制降维后的数据集的散点图\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_pca.loc[df_pca['target'] == 0, 'PCA1'], df_pca.loc[df_pca['target'] == 0, 'PCA2'], c='blue', label='Negative')\n",
    "ax.scatter(df_pca.loc[df_pca['target'] == 1, 'PCA1'], df_pca.loc[df_pca['target'] == 1, 'PCA2'], c='red', label='Positive')\n",
    "ax.legend()\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1] \n",
    "\n",
    "# 实例化分类器，并设置相应的超参数\n",
    "clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=0)\n",
    "\n",
    "# 使用L1正则化训练模型并选择最佳特征子集\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "best_features = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    if clf.coef_[0, i] != 0:\n",
    "        best_features.append(X_train.columns[i]) \n",
    "\n",
    "\n",
    "# 打印最佳特征子集\n",
    "print(best_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1] \n",
    "X_valid = df_valid.iloc[:, :-1]\n",
    "y_valid = df_valid.iloc[:, -1]\n",
    "\n",
    "df_test = pd.read_csv('data_test.csv', header=0)\n",
    "\n",
    "\n",
    "\n",
    "# 对 X_train 中的每一列进行 Label Encoding\n",
    "for col in df_test:\n",
    "    if df_test[col].dtype == 'object':\n",
    "        df_test[col] = encoder.fit_transform(df_test[col].astype(str))\n",
    "\n",
    "\n",
    "\n",
    "# 对fnlwgt列进行特征缩放\n",
    "df_test['fnlwgt'] = scaler.fit_transform(df_test[['fnlwgt']])*100\n",
    "\n",
    "\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]\n",
    "\n",
    "\n",
    "# 构建神经网络模型\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(X_valid, y_valid)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred = np.round(y_pred).astype(int)  \n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# 计算 precision、recall 和 F1-score\n",
    "precision = precision_score(y_valid, y_pred)\n",
    "recall = recall_score(y_valid, y_pred)\n",
    "f1 = f1_score(y_valid, y_pred)\n",
    "\n",
    "\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1] \n",
    "X_valid = df_valid.iloc[:, :-1]\n",
    "y_valid = df_valid.iloc[:, -1]\n",
    "\n",
    "df_test = pd.read_csv('data_test.csv', header=0)\n",
    "\n",
    "\n",
    "\n",
    "# 对 X_train 中的每一列进行 Label Encoding\n",
    "for col in df_test:\n",
    "    if df_test[col].dtype == 'object':\n",
    "        df_test[col] = encoder.fit_transform(df_test[col].astype(str))\n",
    "\n",
    "\n",
    "\n",
    "# 对fnlwgt列进行特征缩放\n",
    "df_test['fnlwgt'] = scaler.fit_transform(df_test[['fnlwgt']])*100\n",
    "\n",
    "\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]\n",
    "\n",
    "\n",
    "# 将 Pandas DataFrame 转换为 NumPy 数组\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "# 将 NumPy 数组转换为 PyTorch Tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 将 NumPy 数组转换为 PyTorch Tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# 定义神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=X_train.shape[1], out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型和优化器\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        # 将数据转换为张量\n",
    "        inputs = torch.Tensor(X_train[i:i+batch_size])\n",
    "        labels = torch.Tensor(y_train[i:i+batch_size]).unsqueeze(1)\n",
    "\n",
    "        # 前向传播、计算损失和反向传播\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计损失\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 在验证集上进行验证\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.Tensor(X_valid)\n",
    "        labels = torch.Tensor(y_valid).unsqueeze(1)\n",
    "        outputs = net(inputs)\n",
    "        val_loss = criterion(outputs, labels)\n",
    "        val_preds = outputs.round().squeeze().detach().numpy()\n",
    "        val_labels = labels.squeeze().detach().numpy()\n",
    "        val_accuracy = np.mean(val_preds == val_labels)\n",
    "        val_precision = precision_score(val_labels, val_preds)\n",
    "        val_recall = recall_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {running_loss / (X_train.shape[0] / batch_size):.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}, Validation F1-Score: {val_f1:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = torch.Tensor(X_test)\n",
    "    print(y_test.shape)\n",
    "    labels = torch.Tensor(y_test).unsqueeze(1)\n",
    "    outputs = net(inputs)\n",
    "    print(labels.shape, outputs.shape)\n",
    "    labels = torch.round(labels)\n",
    "    print(labels)\n",
    "    test_loss = criterion(outputs, labels)\n",
    "    test_preds = outputs.round().squeeze().detach().numpy()\n",
    "    test_labels = labels.squeeze().detach().numpy()\n",
    "    test_accuracy = np.mean(test_preds == test_labels)\n",
    "    test_precision = precision_score(test_labels, test_preds)\n",
    "    test_recall = recall_score(test_labels, test_preds)\n",
    "    test_f1 = f1_score(test_labels, test_preds)\n",
    "    \n",
    "print('Precision: {:.4f}'.format(test_precision))\n",
    "print('Recall: {:.4f}'.format(test_recall))\n",
    "print('F1-score: {:.4f}'.format(test_f1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
