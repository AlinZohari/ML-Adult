{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect and Explore the Data\n",
    "Take a look at these data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "(16281, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"data/data_train.csv\")\n",
    "data_test = pd.read_csv(\"data/data_test.csv\")\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  educational_num  \\\n",
       "0   39         State-gov   77516  Bachelors               13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors               13   \n",
       "2   38           Private  215646    HS-grad                9   \n",
       "3   53           Private  234721       11th                7   \n",
       "4   28           Private  338409  Bachelors               13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States       0  \n",
       "1             0             0              13  United-States       0  \n",
       "2             0             0              40  United-States       0  \n",
       "3             0             0              40  United-States       0  \n",
       "4             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational_num  capital-gain  \\\n",
       "count  32561.000000  3.256100e+04     32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05        10.080679   1077.648844   \n",
       "std       13.640433  1.055500e+05         2.572720   7385.292085   \n",
       "min       17.000000  1.228500e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05        12.000000      0.000000   \n",
       "max       90.000000  1.484705e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  32561.000000    32561.000000  32561.000000  \n",
       "mean      87.303830       40.437456      0.240810  \n",
       "std      402.960219       12.347429      0.427581  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     4356.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational_num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18    Private  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4     Prof-specialty    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  income  \n",
       "0              40  United-States       0  \n",
       "1              50  United-States       0  \n",
       "2              40  United-States       1  \n",
       "3              40  United-States       1  \n",
       "4              30  United-States       0  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16281.000000</td>\n",
       "      <td>1.628100e+04</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.767459</td>\n",
       "      <td>1.894357e+05</td>\n",
       "      <td>10.072907</td>\n",
       "      <td>1081.905104</td>\n",
       "      <td>87.899269</td>\n",
       "      <td>40.392236</td>\n",
       "      <td>0.236226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.849187</td>\n",
       "      <td>1.057149e+05</td>\n",
       "      <td>2.567545</td>\n",
       "      <td>7583.935968</td>\n",
       "      <td>403.105286</td>\n",
       "      <td>12.479332</td>\n",
       "      <td>0.424776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.167360e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.778310e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.383840e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational_num  capital-gain  \\\n",
       "count  16281.000000  1.628100e+04     16281.000000  16281.000000   \n",
       "mean      38.767459  1.894357e+05        10.072907   1081.905104   \n",
       "std       13.849187  1.057149e+05         2.567545   7583.935968   \n",
       "min       17.000000  1.349200e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.167360e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.778310e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.383840e+05        12.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  16281.000000    16281.000000  16281.000000  \n",
       "mean      87.899269       40.392236      0.236226  \n",
       "std      403.105286       12.479332      0.424776  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     3770.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "workclass          object\n",
      "fnlwgt              int64\n",
      "education          object\n",
      "educational_num     int64\n",
      "marital-status     object\n",
      "occupation         object\n",
      "relationship       object\n",
      "race               object\n",
      "gender             object\n",
      "capital-gain        int64\n",
      "capital-loss        int64\n",
      "hours-per-week      int64\n",
      "native-country     object\n",
      "income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "workclass          object\n",
      "fnlwgt              int64\n",
      "education          object\n",
      "educational_num     int64\n",
      "marital-status     object\n",
      "occupation         object\n",
      "relationship       object\n",
      "race               object\n",
      "gender             object\n",
      "capital-gain        int64\n",
      "capital-loss        int64\n",
      "hours-per-week      int64\n",
      "native-country     object\n",
      "income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_test.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "As everyone might have different preprocess actions towards the training dataset, it is necessary to perform corresponding preprocess actions to the testing set and then it can be used to test different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Prepare train and validation data for the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data_train['workclass'] = encoder.fit_transform(data_train['workclass'])\n",
    "data_train['marital-status'] = encoder.fit_transform(\n",
    "    data_train['marital-status'])\n",
    "data_train['occupation'] = encoder.fit_transform(data_train['occupation'])\n",
    "data_train['relationship'] = encoder.fit_transform(data_train['relationship'])\n",
    "data_train['race'] = encoder.fit_transform(data_train['race'])\n",
    "data_train['gender'] = encoder.fit_transform(data_train['gender'])\n",
    "data_train['native-country'] = encoder.fit_transform(\n",
    "    data_train['native-country'])\n",
    "\n",
    "# Preprocessed test set for decision tree\n",
    "x_train = data_train[feature_names]\n",
    "y_train = data_train['income']\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_tree, x_val_tree, y_train_tree, y_val_tree = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(x_train_tree.shape)\n",
    "# print(x_val_tree.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Prepare test data for the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data_test['workclass'] = encoder.fit_transform(data_test['workclass'])\n",
    "data_test['marital-status'] = encoder.fit_transform(\n",
    "    data_test['marital-status'])\n",
    "data_test['occupation'] = encoder.fit_transform(data_test['occupation'])\n",
    "data_test['relationship'] = encoder.fit_transform(data_test['relationship'])\n",
    "data_test['race'] = encoder.fit_transform(data_test['race'])\n",
    "data_test['gender'] = encoder.fit_transform(data_test['gender'])\n",
    "data_test['native-country'] = encoder.fit_transform(\n",
    "    data_test['native-country'])\n",
    "\n",
    "# Preprocessed test set for decision tree\n",
    "x_test_tree = data_test[feature_names]\n",
    "y_test_tree = data_test['income']\n",
    "\n",
    "# Preprocessed test set\n",
    "# print(x_test_tree)\n",
    "# print(y_test_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 K-NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Prepare train and validation data for the k-NN\n",
    "Load the data and encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40875606 -1.88422155  0.08005085 ... -0.21799808  0.77946024\n",
      "   0.26333357]\n",
      " [-0.1888573  -0.0841701  -0.98165286 ...  4.45716784  0.77946024\n",
      "   0.26333357]\n",
      " [ 1.42373357  1.71588136  0.126197   ... -0.21799808 -0.03151042\n",
      "   0.26333357]\n",
      " ...\n",
      " [-1.50824984 -0.0841701   0.25206312 ... -0.21799808 -1.65345173\n",
      "   0.26333357]\n",
      " [ 0.83733689  1.71588136 -1.28762772 ... -0.21799808  3.53676046\n",
      "   0.26333357]\n",
      " [-0.33545648  0.81585563 -0.59020877 ... -0.21799808  1.59043089\n",
      "   0.26333357]]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "\n",
    "# transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_train\n",
    "le = LabelEncoder()\n",
    "test_knn = []\n",
    "for col in cat_columns:\n",
    "    data_train[col] = le.fit_transform(data_train[col])\n",
    "\n",
    "# Split the test set\n",
    "x_train = data_train.drop(columns =['income'])\n",
    "y_train = data_train['income']\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_knn, x_val_knn, y_train_knn, y_val_knn = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(x_train_knn.shape)\n",
    "# print(x_val_knn.shape)\n",
    "\n",
    "#Standard Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train_knn = preprocessing.StandardScaler().fit(x_train_knn).transform(x_train_knn.astype(float))\n",
    "print(x_train_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Prepare test data for the k-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "# transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_test\n",
    "le = LabelEncoder()\n",
    "test_knn = []\n",
    "for col in cat_columns:\n",
    "    data_test[col] = le.fit_transform(data_test[col])\n",
    "\n",
    "# Split the test set\n",
    "x_test_knn = data_test.drop(columns =['income'])\n",
    "y_test_knn = data_test['income']\n",
    "\n",
    "# Print the first 5 rows of the transformed dataset\n",
    "# print(x_test_knn.head())\n",
    "# print(y_test_knn.head())\n",
    "\n",
    "#Standard Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_test_knn = preprocessing.StandardScaler().fit(x_test_knn).transform(x_test_knn.astype(float))\n",
    "# print(x_test_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Prepare train and validation data for the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 14)\n",
      "(6513, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv', header=0)\n",
    "\n",
    "# feature transformation\n",
    "for col in data_train:\n",
    "    if data_train[col].dtype == 'object':\n",
    "        data_train[col] = encoder.fit_transform(data_train[col].astype(str))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "for col in data_train.columns:\n",
    "    data_train[col] = scaler.fit_transform(data_train[[col]])\n",
    "\n",
    "x_train = data_train.iloc[:, :-1]\n",
    "y_train = data_train.iloc[:, -1]\n",
    "# print(x_test_nn)\n",
    "# print(y_test_nn)\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_nn, x_val_nn, y_train_nn, y_val_nn = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train_nn.shape)\n",
    "print(x_val_nn.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Prepare test data for the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv', header=0)\n",
    "\n",
    "# feature transformation\n",
    "for col in data_test:\n",
    "    if data_test[col].dtype == 'object':\n",
    "        data_test[col] = encoder.fit_transform(data_test[col].astype(str))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "for col in data_test.columns:\n",
    "    data_test[col] = scaler.fit_transform(data_test[[col]])\n",
    "\n",
    "x_test_nn = data_test.iloc[:, :-1]\n",
    "y_test_nn = data_test.iloc[:, -1]\n",
    "# print(x_test_nn)\n",
    "# print(y_test_nn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bayesian Leanring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Prepare train data and validation for the Bayesian learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the tain data\n",
    "import pandas as pd\n",
    "data_test = pd.read_csv('data/data_train.csv')\n",
    "data_test = data_test.reset_index()\n",
    "xs_test = data_test.drop(['income'], axis=1)\n",
    "ys_test = data_test['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
      "There are 7 numerical variables\n",
      "\n",
      "The numerical variables are :\n",
      "\n",
      " ['index', 'age', 'fnlwgt', 'educational_num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "#Store all the categorical features\n",
    "categorical = [var for var in xs_test.columns if xs_test[var].dtype=='O']\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "#Store all the numerical features\n",
    "numerical = [var for var in xs_test.columns if xs_test[var].dtype!='O']\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "print('The numerical variables are :\\n\\n', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Discretization the numerical features##\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#Age\n",
    "age_t = xs_test['age']\n",
    "age_t=age_t.values.reshape(-1,1)\n",
    "age_trans_t = kbins.fit_transform(age_t)\n",
    "\n",
    "#Final weight\n",
    "fw_t = xs_test['fnlwgt']\n",
    "fw_t=fw_t.values.reshape(-1,1)\n",
    "fw_trans_t = kbins.fit_transform(fw_t)\n",
    "\n",
    "#educational_num\n",
    "edunum_t = xs_test['educational_num']\n",
    "edunum_t=edunum_t.values.reshape(-1,1)\n",
    "edunum_trans_t = kbins.fit_transform(edunum_t)\n",
    "\n",
    "#capital gain\n",
    "cg_t = xs_test['capital-gain']\n",
    "cg_t=cg_t.values.reshape(-1,1)\n",
    "cg_trans_t = kbins.fit_transform(cg_t)\n",
    "\n",
    "#capital loss\n",
    "cl_t = xs_test['capital-loss']\n",
    "cl_t=cl_t.values.reshape(-1,1)\n",
    "cl_trans_t = kbins.fit_transform(cl_t)\n",
    "\n",
    "#hours-per-week\n",
    "hours_t = xs_test['hours-per-week']\n",
    "hours_t=hours_t.values.reshape(-1,1)\n",
    "hours_trans_t = kbins.fit_transform(hours_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_t=pd.DataFrame(age_trans_t,columns =['age'])\n",
    "fw_t=pd.DataFrame(fw_trans_t,columns =['fnlwgt'])\n",
    "edunum_t=pd.DataFrame(edunum_trans_t,columns =['educational-num'])\n",
    "cg_t=pd.DataFrame(cg_trans_t,columns =['capital-gain'])\n",
    "cl_t=pd.DataFrame(cl_trans_t,columns =['capital-loss'])\n",
    "hours_t=pd.DataFrame(hours_trans_t,columns =['hours-per-week'])\n",
    "\n",
    "\n",
    "numerical_trans_t = pd.concat([age_t,fw_t,edunum_t,cg_t,cl_t,hours_t],axis=1)\n",
    "\n",
    "xs_bnb_test = pd.concat([xs_test[categorical],numerical_trans_t],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 154)\n",
      "(6513, 154)\n"
     ]
    }
   ],
   "source": [
    "#install encoder library\n",
    "# !pip install category_encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "#import the trained encoder_bnb\n",
    "import pickle\n",
    "with open(\"trained_models/encoder_bnb.pkl\", \"rb\") as f:\n",
    "    encoder_bnb = pickle.load(f)\n",
    "\n",
    "#Encode the unseen test data\n",
    "# xs_bnb_test = encoder_bnb.transform(xs_bnb_test)\n",
    "# ys_bnb_test = ys_test\n",
    "\n",
    "x_train = encoder_bnb.transform(xs_bnb_test)\n",
    "y_train = ys_test\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_nb, x_val_nb, y_train_nb, y_val_nb = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train_nb.shape)\n",
    "print(x_val_nb.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Prepare test for the Bayesian learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
      "There are 7 numerical variables\n",
      "\n",
      "The numerical variables are :\n",
      "\n",
      " ['index', 'age', 'fnlwgt', 'educational_num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "#Importing the testing data\n",
    "import pandas as pd\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "data_test = data_test.reset_index()\n",
    "xs_test = data_test.drop(['income'], axis=1)\n",
    "ys_test = data_test['income']\n",
    "\n",
    "#Store all the categorical features\n",
    "categorical = [var for var in xs_test.columns if xs_test[var].dtype=='O']\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "#Store all the numerical features\n",
    "numerical = [var for var in xs_test.columns if xs_test[var].dtype!='O']\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "print('The numerical variables are :\\n\\n', numerical)\n",
    "\n",
    "# Discretization the numerical features##\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#Age\n",
    "age_t = xs_test['age']\n",
    "age_t=age_t.values.reshape(-1,1)\n",
    "age_trans_t = kbins.fit_transform(age_t)\n",
    "\n",
    "#Final weight\n",
    "fw_t = xs_test['fnlwgt']\n",
    "fw_t=fw_t.values.reshape(-1,1)\n",
    "fw_trans_t = kbins.fit_transform(fw_t)\n",
    "\n",
    "#educational_num\n",
    "edunum_t = xs_test['educational_num']\n",
    "edunum_t=edunum_t.values.reshape(-1,1)\n",
    "edunum_trans_t = kbins.fit_transform(edunum_t)\n",
    "\n",
    "#capital gain\n",
    "cg_t = xs_test['capital-gain']\n",
    "cg_t=cg_t.values.reshape(-1,1)\n",
    "cg_trans_t = kbins.fit_transform(cg_t)\n",
    "\n",
    "#capital loss\n",
    "cl_t = xs_test['capital-loss']\n",
    "cl_t=cl_t.values.reshape(-1,1)\n",
    "cl_trans_t = kbins.fit_transform(cl_t)\n",
    "\n",
    "#hours-per-week\n",
    "hours_t = xs_test['hours-per-week']\n",
    "hours_t=hours_t.values.reshape(-1,1)\n",
    "hours_trans_t = kbins.fit_transform(hours_t)\n",
    "\n",
    "age_t=pd.DataFrame(age_trans_t,columns =['age'])\n",
    "fw_t=pd.DataFrame(fw_trans_t,columns =['fnlwgt'])\n",
    "edunum_t=pd.DataFrame(edunum_trans_t,columns =['educational-num'])\n",
    "cg_t=pd.DataFrame(cg_trans_t,columns =['capital-gain'])\n",
    "cl_t=pd.DataFrame(cl_trans_t,columns =['capital-loss'])\n",
    "hours_t=pd.DataFrame(hours_trans_t,columns =['hours-per-week'])\n",
    "\n",
    "\n",
    "numerical_trans_t = pd.concat([age_t,fw_t,edunum_t,cg_t,cl_t,hours_t],axis=1)\n",
    "\n",
    "xs_bnb_test = pd.concat([xs_test[categorical],numerical_trans_t],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# import the trained encoder_bnb\n",
    "import pickle\n",
    "with open(\"trained_models/encoder_bnb.pkl\", \"rb\") as f:\n",
    "    encoder_bnb = pickle.load(f)\n",
    "\n",
    "#Encode the unseen test data\n",
    "# xs_bnb_test = encoder_bnb.transform(xs_bnb_test)\n",
    "# ys_bnb_test = ys_test\n",
    "\n",
    "x_test_nb = encoder_bnb.transform(xs_bnb_test)\n",
    "y_test_nb = ys_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict the Result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Result of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=9, max_features=8, min_samples_leaf=10,\n",
      "                       min_samples_split=8)\n",
      "[0 0 0 ... 1 0 1]\n",
      "(16281,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the decision tree\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Load model\n",
    "with open('trained_models/pruned_decision_tree.pkl', 'rb') as f:\n",
    "    decision_tree = pickle.load(f)\n",
    "\n",
    "print(decision_tree)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_tree_proba = decision_tree.predict_proba(x_train_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_tree_proba)\n",
    "# print(y_pred_tree_proba.shape)\n",
    "y_pred_tree = decision_tree.predict(x_train_tree)  # binary\n",
    "# print(y_pred_tree)\n",
    "# print(y_pred_tree.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_tree_proba = decision_tree.predict_proba(x_val_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_val_tree_proba)\n",
    "# print(y_pred_val_tree_proba.shape)\n",
    "y_pred_val_tree = decision_tree.predict(x_val_tree)  # binary\n",
    "# print(y_pred_val_tree)\n",
    "# print(y_pred_val_tree.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_tree_proba = decision_tree.predict_proba(x_test_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_test_tree_proba)\n",
    "# print(y_pred_test_tree_proba.shape)\n",
    "y_pred_test_tree = decision_tree.predict(x_test_tree)  # binary\n",
    "# print(y_pred_test_tree)\n",
    "# print(y_pred_test_tree.shape)\n",
    "\n",
    "\n",
    "# Evaluate training\n",
    "# print(classification_report(y_train_tree,y_pred_tree_proba > 0.5))\n",
    "# auc = roc_auc_score(y_train_tree, y_pred_tree_proba > 0.5)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Result of k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=16, metric='manhattan', n_neighbors=29)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     19778\n",
      "           1       0.73      0.60      0.66      6270\n",
      "\n",
      "    accuracy                           0.85     26048\n",
      "   macro avg       0.81      0.76      0.78     26048\n",
      "weighted avg       0.84      0.85      0.84     26048\n",
      "\n",
      "ROC_AUC score: 0.7638\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load k-NN model\n",
    "knn_model = joblib.load('trained_models/kNN.pkl')\n",
    "print(knn_model)\n",
    "\n",
    "# Produce results\n",
    "y_pred_knn_proba = knn_model.predict_proba(x_train_knn)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_knn_proba)\n",
    "# print(y_pred_knn_proba.shape)\n",
    "\n",
    "y_pred_knn = knn_model.predict(x_train_knn)\n",
    "# print(y_pred_knn)\n",
    "# print(y_pred_knn.shape)\n",
    "\n",
    "# Evaluate the the model\n",
    "print(classification_report(y_train_knn,y_pred_knn))\n",
    "auc = roc_auc_score(y_train_knn,y_pred_knn)  # ROC score\n",
    "print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Result of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 14)\n",
      "814/814 [==============================] - 1s 829us/step\n",
      "[0 0 0 ... 1 0 1]\n",
      "(16281,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     19778\n",
      "         1.0       0.77      0.57      0.65      6270\n",
      "\n",
      "    accuracy                           0.85     26048\n",
      "   macro avg       0.82      0.76      0.78     26048\n",
      "weighted avg       0.85      0.85      0.85     26048\n",
      "\n",
      "ROC_AUC score: 0.7561\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load neutral network model\n",
    "nn_model = keras.models.load_model('trained_models/NeuralNetwork.h5')\n",
    "# nn_model.summary()\n",
    "\n",
    "# print(x_train_nn)\n",
    "# print(x_train_nn.shape)\n",
    "\n",
    "# Produce results\n",
    "y_pred_nn_proba = nn_model.predict(x_train_nn)  # probability of \">50k\"\n",
    "y_pred_nn_proba = np.squeeze(y_pred_nn_proba)  # to 1-d array\n",
    "print(y_pred_nn_prob)\n",
    "print(y_pred_nn_prob.shape)\n",
    "\n",
    "y_pred_nn = np.where(y_pred_nn_proba > 0.5, 1, 0)  # probability to 0/1\n",
    "# print(y_pred_nn)\n",
    "# print(y_pred_nn.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_train_nn,y_pred_nn))\n",
    "auc = roc_auc_score(y_train_nn, y_pred_nn)  # ROC score\n",
    "print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Result of Bayesian learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88     19778\n",
      "           1       0.63      0.65      0.64      6270\n",
      "\n",
      "    accuracy                           0.83     26048\n",
      "   macro avg       0.76      0.77      0.76     26048\n",
      "weighted avg       0.83      0.83      0.83     26048\n",
      "\n",
      "ROC_AUC score: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator BernoulliNB from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nb_model = pickle.load(open('trained_models/BernoullilNaiveBayes.sav', 'rb'))\n",
    "\n",
    "\n",
    "y_pred_nb_proba = nb_model.predict_proba(x_train_nb)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_nb_proba)\n",
    "# print(y_pred_nb_proba.shape)\n",
    "\n",
    "y_pred_nb = nb_model.predict(x_train_nb)\n",
    "# print(y_pred_nb)\n",
    "# print(y_pred_nb.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_train_nb,y_pred_nb))\n",
    "auc = roc_auc_score(y_train_nb, y_pred_nb)  # ROC score\n",
    "print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Majority Voting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Custom Esemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "class EnsembleModel():\n",
    "\n",
    "    def __init__(self, predictions, voting):\n",
    "        self.predictions = predictions  # prediction of base classifiers; shape: (num_of_base_models, num_of_test_instances)\n",
    "        self.voting = voting\n",
    "        \n",
    "\n",
    "    def predict(self, weights=[]):\n",
    "        # Stack the predictions into a single array\n",
    "        predictions_stack = np.stack(predictions)\n",
    "        \n",
    "        # print(predictions.shape)\n",
    "        if (self.voting == \"soft\"):\n",
    "            # Soft Voting\n",
    "            # Compute the weighted average of the predictions along the first axis (i.e., across each column)\n",
    "            if (weights == []):\n",
    "                # Default: weights are equal\n",
    "                soft_pred_prob = np.average(predictions_stack, axis=0)\n",
    "            else:\n",
    "                # Use passing weights\n",
    "                soft_pred_prob = np.average(predictions_stack, axis=0, weights=weights)\n",
    "\n",
    "            soft_pred = np.where(soft_pred_prob > 0.5, 1, 0)  # probability to 0/1\n",
    "            return soft_pred\n",
    "        else:\n",
    "            # Hard Voting\n",
    "            # Compute the mode of the predictions along the first axis (i.e., across each column)\n",
    "            mode_pred = mode(predictions_stack, axis=0).mode\n",
    "            mode_pred = np.transpose(mode_pred) \n",
    "            mode_pred = np.squeeze(mode_pred)\n",
    "            # print(mode_pred)\n",
    "            # print(mode_pred.shape)\n",
    "            return mode_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hard Voting VS. Soft Voting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/nxhg4vsx36x27z5gtvc6ylk00000gn/T/ipykernel_8386/2981906179.py:30: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_pred = mode(predictions_stack, axis=0).mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     12435\n",
      "           1       0.78      0.52      0.62      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.82      0.74      0.77     16281\n",
      "weighted avg       0.84      0.85      0.84     16281\n",
      "\n",
      "ROC_AUC score: 0.7366\n"
     ]
    }
   ],
   "source": [
    "predictions = [y_pred_tree, y_pred_knn, y_pred_nn, y_pred_nb]  # binary predictions\n",
    "\n",
    "e = EnsembleModel(predictions, \"hard\")\n",
    "hard_pred = e.predict()\n",
    "# print(hard_pred)\n",
    "# print(hard_pred.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test,hard_pred))\n",
    "auc = roc_auc_score(y_test, hard_pred)  # ROC score\n",
    "print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     12435\n",
      "           1       0.75      0.57      0.65      3846\n",
      "\n",
      "    accuracy                           0.86     16281\n",
      "   macro avg       0.82      0.76      0.78     16281\n",
      "weighted avg       0.85      0.86      0.85     16281\n",
      "\n",
      "ROC_AUC score: 0.7579\n"
     ]
    }
   ],
   "source": [
    "predictions = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions\n",
    "# weights = [1, 1, 1, 1]\n",
    "\n",
    "e = EnsembleModel(predictions, \"soft\")\n",
    "soft_pred = e.predict()\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test,soft_pred))\n",
    "auc = roc_auc_score(y_test, soft_pred)  # ROC score\n",
    "print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Hyper-parameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Test domination of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When decision tree is dominate:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     12435\n",
      "           1       0.77      0.54      0.64      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.82      0.75      0.77     16281\n",
      "weighted avg       0.85      0.85      0.84     16281\n",
      "\n",
      "ROC_AUC score: 0.7459\n",
      "\n",
      "\n",
      "When k-NN is dominate:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     12435\n",
      "           1       0.70      0.57      0.63      3846\n",
      "\n",
      "    accuracy                           0.84     16281\n",
      "   macro avg       0.79      0.75      0.76     16281\n",
      "weighted avg       0.83      0.84      0.84     16281\n",
      "\n",
      "ROC_AUC score: 0.7463\n",
      "\n",
      "\n",
      "When neutral network is dominate:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     12435\n",
      "           1       0.74      0.55      0.63      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.80      0.74      0.77     16281\n",
      "weighted avg       0.84      0.85      0.84     16281\n",
      "\n",
      "ROC_AUC score: 0.7430\n",
      "\n",
      "\n",
      "When Bernoullil Naive Bayes (BNB) is dominate:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     12435\n",
      "           1       0.63      0.65      0.64      3846\n",
      "\n",
      "    accuracy                           0.83     16281\n",
      "   macro avg       0.76      0.76      0.76     16281\n",
      "weighted avg       0.83      0.83      0.83     16281\n",
      "\n",
      "ROC_AUC score: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Stack the predictions into a single array\n",
    "# predictions = np.stack((y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba))\n",
    "\n",
    "weights1 = [0.7, 0.1, 0.1, 0.1]\n",
    "weights2 = [0.1, 0.7, 0.1, 0.1]\n",
    "weights3 = [0.1, 0.1, 0.7, 0.1]\n",
    "weights4 = [0.1, 0.1, 0.1, 0.7]\n",
    "\n",
    "soft_pred_prob1 = np.average(predictions, axis=0, weights=weights1)\n",
    "soft_pred_prob2 = np.average(predictions, axis=0, weights=weights2)\n",
    "soft_pred_prob3 = np.average(predictions, axis=0, weights=weights3)\n",
    "soft_pred_prob4 = np.average(predictions, axis=0, weights=weights4)\n",
    "\n",
    "# print(soft_pred_prob)\n",
    "# print(soft_pred_prob.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"When decision tree is dominate:\")\n",
    "print(classification_report(y_test,soft_pred_prob1>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob1>0.5)))\n",
    "\n",
    "print(\"\\n\\nWhen k-NN is dominate:\")\n",
    "print(classification_report(y_test,soft_pred_prob2>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob2>0.5)))\n",
    "\n",
    "print(\"\\n\\nWhen neutral network is dominate:\")\n",
    "print(classification_report(y_test,soft_pred_prob3>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob3>0.5)))\n",
    "\n",
    "print(\"\\n\\nWhen Bernoullil Naive Bayes (BNB) is dominate:\")\n",
    "print(classification_report(y_test,soft_pred_prob4>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob4>0.5)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Attemp improving the preformance\n",
    "Now that we know when Bernoullil Naive Bayes is dominate, the performance is better. Next, we want to try lifting and decrising its weight, and see if we can further improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give weight 0.8 to BNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     12435\n",
      "           1       0.63      0.65      0.64      3846\n",
      "\n",
      "    accuracy                           0.83     16281\n",
      "   macro avg       0.76      0.76      0.76     16281\n",
      "weighted avg       0.83      0.83      0.83     16281\n",
      "\n",
      "ROC_AUC score: 0.7647\n",
      "\n",
      "\n",
      "Give weight 0.9 to BNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     12435\n",
      "           1       0.63      0.65      0.64      3846\n",
      "\n",
      "    accuracy                           0.83     16281\n",
      "   macro avg       0.76      0.76      0.76     16281\n",
      "weighted avg       0.83      0.83      0.83     16281\n",
      "\n",
      "ROC_AUC score: 0.7647\n",
      "\n",
      "\n",
      "Give weight 1 to BNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     12435\n",
      "           1       0.63      0.65      0.64      3846\n",
      "\n",
      "    accuracy                           0.83     16281\n",
      "   macro avg       0.76      0.76      0.76     16281\n",
      "weighted avg       0.83      0.83      0.83     16281\n",
      "\n",
      "ROC_AUC score: 0.7647\n",
      "\n",
      "\n",
      "Give weight 0.1 to BNB and 0.3 to other models:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     12435\n",
      "           1       0.77      0.56      0.65      3846\n",
      "\n",
      "    accuracy                           0.86     16281\n",
      "   macro avg       0.82      0.75      0.78     16281\n",
      "weighted avg       0.85      0.86      0.85     16281\n",
      "\n",
      "ROC_AUC score: 0.7537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights1 = [0.067, 0.067, 0.066, 0.8]\n",
    "weights2 = [0.034, 0.034, 0.034, 0.9]\n",
    "weights3 = [0, 0, 0, 1]\n",
    "weights4 = [0.3, 0.3, 0.3, 0.1]\n",
    "\n",
    "soft_pred_prob1 = np.average(predictions, axis=0, weights=weights1)\n",
    "soft_pred_prob2 = np.average(predictions, axis=0, weights=weights2)\n",
    "soft_pred_prob3 = np.average(predictions, axis=0, weights=weights3)\n",
    "soft_pred_prob4 = np.average(predictions, axis=0, weights=weights4)\n",
    "\n",
    "# print(soft_pred_prob)\n",
    "# print(soft_pred_prob.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Give weight 0.8 to BNB:\")\n",
    "print(classification_report(y_test,soft_pred_prob1>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob1>0.5)))\n",
    "\n",
    "print(\"\\n\\nGive weight 0.9 to BNB:\")\n",
    "print(classification_report(y_test,soft_pred_prob2>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob2>0.5)))\n",
    "\n",
    "print(\"\\n\\nGive weight 1 to BNB:\")\n",
    "print(classification_report(y_test,soft_pred_prob3>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob3>0.5)))\n",
    "\n",
    "print(\"\\n\\nGive weight 0.1 to BNB and 0.3 to other models:\")\n",
    "print(classification_report(y_test,soft_pred_prob4>0.5))\n",
    "print('ROC_AUC score: {:.4f}'.format(roc_auc_score(y_test,soft_pred_prob4>0.5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Result Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
