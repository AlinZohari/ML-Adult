{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect and Explore the Data\n",
    "Take a look at these data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "(16281, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"data/data_train.csv\")\n",
    "data_test = pd.read_csv(\"data/data_test.csv\")\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  educational_num  \\\n",
       "0   39         State-gov   77516  Bachelors               13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors               13   \n",
       "2   38           Private  215646    HS-grad                9   \n",
       "3   53           Private  234721       11th                7   \n",
       "4   28           Private  338409  Bachelors               13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States       0  \n",
       "1             0             0              13  United-States       0  \n",
       "2             0             0              40  United-States       0  \n",
       "3             0             0              40  United-States       0  \n",
       "4             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational_num  capital-gain  \\\n",
       "count  32561.000000  3.256100e+04     32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05        10.080679   1077.648844   \n",
       "std       13.640433  1.055500e+05         2.572720   7385.292085   \n",
       "min       17.000000  1.228500e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05        12.000000      0.000000   \n",
       "max       90.000000  1.484705e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  32561.000000    32561.000000  32561.000000  \n",
       "mean      87.303830       40.437456      0.240810  \n",
       "std      402.960219       12.347429      0.427581  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     4356.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational_num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18    Private  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4     Prof-specialty    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  income  \n",
       "0              40  United-States       0  \n",
       "1              50  United-States       0  \n",
       "2              40  United-States       1  \n",
       "3              40  United-States       1  \n",
       "4              30  United-States       0  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16281.000000</td>\n",
       "      <td>1.628100e+04</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.767459</td>\n",
       "      <td>1.894357e+05</td>\n",
       "      <td>10.072907</td>\n",
       "      <td>1081.905104</td>\n",
       "      <td>87.899269</td>\n",
       "      <td>40.392236</td>\n",
       "      <td>0.236226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.849187</td>\n",
       "      <td>1.057149e+05</td>\n",
       "      <td>2.567545</td>\n",
       "      <td>7583.935968</td>\n",
       "      <td>403.105286</td>\n",
       "      <td>12.479332</td>\n",
       "      <td>0.424776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.167360e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.778310e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.383840e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational_num  capital-gain  \\\n",
       "count  16281.000000  1.628100e+04     16281.000000  16281.000000   \n",
       "mean      38.767459  1.894357e+05        10.072907   1081.905104   \n",
       "std       13.849187  1.057149e+05         2.567545   7583.935968   \n",
       "min       17.000000  1.349200e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.167360e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.778310e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.383840e+05        12.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  16281.000000    16281.000000  16281.000000  \n",
       "mean      87.899269       40.392236      0.236226  \n",
       "std      403.105286       12.479332      0.424776  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     3770.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "workclass          object\n",
      "fnlwgt              int64\n",
      "education          object\n",
      "educational_num     int64\n",
      "marital-status     object\n",
      "occupation         object\n",
      "relationship       object\n",
      "race               object\n",
      "gender             object\n",
      "capital-gain        int64\n",
      "capital-loss        int64\n",
      "hours-per-week      int64\n",
      "native-country     object\n",
      "income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "workclass          object\n",
      "fnlwgt              int64\n",
      "education          object\n",
      "educational_num     int64\n",
      "marital-status     object\n",
      "occupation         object\n",
      "relationship       object\n",
      "race               object\n",
      "gender             object\n",
      "capital-gain        int64\n",
      "capital-loss        int64\n",
      "hours-per-week      int64\n",
      "native-country     object\n",
      "income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_test.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "As everyone might have different preprocess actions towards the training dataset, it is necessary to perform corresponding preprocess actions to the testing set and then it can be used to test different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Prepare train and validation data for the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data_train['workclass'] = encoder.fit_transform(data_train['workclass'])\n",
    "data_train['marital-status'] = encoder.fit_transform(\n",
    "    data_train['marital-status'])\n",
    "data_train['occupation'] = encoder.fit_transform(data_train['occupation'])\n",
    "data_train['relationship'] = encoder.fit_transform(data_train['relationship'])\n",
    "data_train['race'] = encoder.fit_transform(data_train['race'])\n",
    "data_train['gender'] = encoder.fit_transform(data_train['gender'])\n",
    "data_train['native-country'] = encoder.fit_transform(\n",
    "    data_train['native-country'])\n",
    "\n",
    "# Preprocessed test set for decision tree\n",
    "x_train = data_train[feature_names]\n",
    "y_train = data_train['income']\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_tree, x_val_tree, y_train_tree, y_val_tree = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(x_train_tree.shape)\n",
    "# print(x_val_tree.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Prepare test data for the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data_test['workclass'] = encoder.fit_transform(data_test['workclass'])\n",
    "data_test['marital-status'] = encoder.fit_transform(\n",
    "    data_test['marital-status'])\n",
    "data_test['occupation'] = encoder.fit_transform(data_test['occupation'])\n",
    "data_test['relationship'] = encoder.fit_transform(data_test['relationship'])\n",
    "data_test['race'] = encoder.fit_transform(data_test['race'])\n",
    "data_test['gender'] = encoder.fit_transform(data_test['gender'])\n",
    "data_test['native-country'] = encoder.fit_transform(\n",
    "    data_test['native-country'])\n",
    "\n",
    "# Preprocessed test set for decision tree\n",
    "x_test_tree = data_test[feature_names]\n",
    "y_test_tree = data_test['income']\n",
    "\n",
    "# Preprocessed test set\n",
    "# print(x_test_tree)\n",
    "# print(y_test_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 K-NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Prepare train and validation data for the k-NN\n",
    "Load the data and encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40875606 -1.88422155  0.08005085 ... -0.21799808  0.77946024\n",
      "   0.26333357]\n",
      " [-0.1888573  -0.0841701  -0.98165286 ...  4.45716784  0.77946024\n",
      "   0.26333357]\n",
      " [ 1.42373357  1.71588136  0.126197   ... -0.21799808 -0.03151042\n",
      "   0.26333357]\n",
      " ...\n",
      " [-1.50824984 -0.0841701   0.25206312 ... -0.21799808 -1.65345173\n",
      "   0.26333357]\n",
      " [ 0.83733689  1.71588136 -1.28762772 ... -0.21799808  3.53676046\n",
      "   0.26333357]\n",
      " [-0.33545648  0.81585563 -0.59020877 ... -0.21799808  1.59043089\n",
      "   0.26333357]]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "\n",
    "# transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_train\n",
    "le = LabelEncoder()\n",
    "test_knn = []\n",
    "for col in cat_columns:\n",
    "    data_train[col] = le.fit_transform(data_train[col])\n",
    "\n",
    "# Split the test set\n",
    "x_train = data_train.drop(columns =['income'])\n",
    "y_train = data_train['income']\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_knn, x_val_knn, y_train_knn, y_val_knn = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(x_train_knn.shape)\n",
    "# print(x_val_knn.shape)\n",
    "\n",
    "#Standard Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train_knn = preprocessing.StandardScaler().fit(x_train_knn).transform(x_train_knn.astype(float))\n",
    "print(x_train_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Prepare test data for the k-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "# transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_test\n",
    "le = LabelEncoder()\n",
    "test_knn = []\n",
    "for col in cat_columns:\n",
    "    data_test[col] = le.fit_transform(data_test[col])\n",
    "\n",
    "# Split the test set\n",
    "x_test_knn = data_test.drop(columns =['income'])\n",
    "y_test_knn = data_test['income']\n",
    "\n",
    "# Print the first 5 rows of the transformed dataset\n",
    "# print(x_test_knn.head())\n",
    "# print(y_test_knn.head())\n",
    "\n",
    "#Standard Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_test_knn = preprocessing.StandardScaler().fit(x_test_knn).transform(x_test_knn.astype(float))\n",
    "# print(x_test_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Prepare train and validation data for the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 14)\n",
      "(6513, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv', header=0)\n",
    "\n",
    "# feature transformation\n",
    "for col in data_train:\n",
    "    if data_train[col].dtype == 'object':\n",
    "        data_train[col] = encoder.fit_transform(data_train[col].astype(str))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "for col in data_train.columns:\n",
    "    data_train[col] = scaler.fit_transform(data_train[[col]])\n",
    "\n",
    "x_train = data_train.iloc[:, :-1]\n",
    "y_train = data_train.iloc[:, -1]\n",
    "# print(x_test_nn)\n",
    "# print(y_test_nn)\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_nn, x_val_nn, y_train_nn, y_val_nn = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train_nn.shape)\n",
    "print(x_val_nn.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Prepare test data for the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv', header=0)\n",
    "\n",
    "# feature transformation\n",
    "for col in data_test:\n",
    "    if data_test[col].dtype == 'object':\n",
    "        data_test[col] = encoder.fit_transform(data_test[col].astype(str))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "for col in data_test.columns:\n",
    "    data_test[col] = scaler.fit_transform(data_test[[col]])\n",
    "\n",
    "x_test_nn = data_test.iloc[:, :-1]\n",
    "y_test_nn = data_test.iloc[:, -1]\n",
    "# print(x_test_nn)\n",
    "# print(y_test_nn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bayesian Leanring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Prepare train data and validation for the Bayesian learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the tain data\n",
    "import pandas as pd\n",
    "data_test = pd.read_csv('data/data_train.csv')\n",
    "data_test = data_test.reset_index()\n",
    "xs_test = data_test.drop(['income'], axis=1)\n",
    "ys_test = data_test['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
      "There are 7 numerical variables\n",
      "\n",
      "The numerical variables are :\n",
      "\n",
      " ['index', 'age', 'fnlwgt', 'educational_num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "#Store all the categorical features\n",
    "categorical = [var for var in xs_test.columns if xs_test[var].dtype=='O']\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "#Store all the numerical features\n",
    "numerical = [var for var in xs_test.columns if xs_test[var].dtype!='O']\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "print('The numerical variables are :\\n\\n', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Discretization the numerical features##\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#Age\n",
    "age_t = xs_test['age']\n",
    "age_t=age_t.values.reshape(-1,1)\n",
    "age_trans_t = kbins.fit_transform(age_t)\n",
    "\n",
    "#Final weight\n",
    "fw_t = xs_test['fnlwgt']\n",
    "fw_t=fw_t.values.reshape(-1,1)\n",
    "fw_trans_t = kbins.fit_transform(fw_t)\n",
    "\n",
    "#educational_num\n",
    "edunum_t = xs_test['educational_num']\n",
    "edunum_t=edunum_t.values.reshape(-1,1)\n",
    "edunum_trans_t = kbins.fit_transform(edunum_t)\n",
    "\n",
    "#capital gain\n",
    "cg_t = xs_test['capital-gain']\n",
    "cg_t=cg_t.values.reshape(-1,1)\n",
    "cg_trans_t = kbins.fit_transform(cg_t)\n",
    "\n",
    "#capital loss\n",
    "cl_t = xs_test['capital-loss']\n",
    "cl_t=cl_t.values.reshape(-1,1)\n",
    "cl_trans_t = kbins.fit_transform(cl_t)\n",
    "\n",
    "#hours-per-week\n",
    "hours_t = xs_test['hours-per-week']\n",
    "hours_t=hours_t.values.reshape(-1,1)\n",
    "hours_trans_t = kbins.fit_transform(hours_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_t=pd.DataFrame(age_trans_t,columns =['age'])\n",
    "fw_t=pd.DataFrame(fw_trans_t,columns =['fnlwgt'])\n",
    "edunum_t=pd.DataFrame(edunum_trans_t,columns =['educational-num'])\n",
    "cg_t=pd.DataFrame(cg_trans_t,columns =['capital-gain'])\n",
    "cl_t=pd.DataFrame(cl_trans_t,columns =['capital-loss'])\n",
    "hours_t=pd.DataFrame(hours_trans_t,columns =['hours-per-week'])\n",
    "\n",
    "\n",
    "numerical_trans_t = pd.concat([age_t,fw_t,edunum_t,cg_t,cl_t,hours_t],axis=1)\n",
    "\n",
    "xs_bnb_test = pd.concat([xs_test[categorical],numerical_trans_t],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 154)\n",
      "(6513, 154)\n"
     ]
    }
   ],
   "source": [
    "#install encoder library\n",
    "# !pip install category_encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "#import the trained encoder_bnb\n",
    "import pickle\n",
    "with open(\"trained_models/encoder_bnb.pkl\", \"rb\") as f:\n",
    "    encoder_bnb = pickle.load(f)\n",
    "\n",
    "#Encode the unseen test data\n",
    "# xs_bnb_test = encoder_bnb.transform(xs_bnb_test)\n",
    "# ys_bnb_test = ys_test\n",
    "\n",
    "x_train = encoder_bnb.transform(xs_bnb_test)\n",
    "y_train = ys_test\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_nb, x_val_nb, y_train_nb, y_val_nb = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train_nb.shape)\n",
    "print(x_val_nb.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Prepare test for the Bayesian learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
      "There are 7 numerical variables\n",
      "\n",
      "The numerical variables are :\n",
      "\n",
      " ['index', 'age', 'fnlwgt', 'educational_num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "#Importing the testing data\n",
    "import pandas as pd\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "data_test = data_test.reset_index()\n",
    "xs_test = data_test.drop(['income'], axis=1)\n",
    "ys_test = data_test['income']\n",
    "\n",
    "#Store all the categorical features\n",
    "categorical = [var for var in xs_test.columns if xs_test[var].dtype=='O']\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "#Store all the numerical features\n",
    "numerical = [var for var in xs_test.columns if xs_test[var].dtype!='O']\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "print('The numerical variables are :\\n\\n', numerical)\n",
    "\n",
    "# Discretization the numerical features##\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#Age\n",
    "age_t = xs_test['age']\n",
    "age_t=age_t.values.reshape(-1,1)\n",
    "age_trans_t = kbins.fit_transform(age_t)\n",
    "\n",
    "#Final weight\n",
    "fw_t = xs_test['fnlwgt']\n",
    "fw_t=fw_t.values.reshape(-1,1)\n",
    "fw_trans_t = kbins.fit_transform(fw_t)\n",
    "\n",
    "#educational_num\n",
    "edunum_t = xs_test['educational_num']\n",
    "edunum_t=edunum_t.values.reshape(-1,1)\n",
    "edunum_trans_t = kbins.fit_transform(edunum_t)\n",
    "\n",
    "#capital gain\n",
    "cg_t = xs_test['capital-gain']\n",
    "cg_t=cg_t.values.reshape(-1,1)\n",
    "cg_trans_t = kbins.fit_transform(cg_t)\n",
    "\n",
    "#capital loss\n",
    "cl_t = xs_test['capital-loss']\n",
    "cl_t=cl_t.values.reshape(-1,1)\n",
    "cl_trans_t = kbins.fit_transform(cl_t)\n",
    "\n",
    "#hours-per-week\n",
    "hours_t = xs_test['hours-per-week']\n",
    "hours_t=hours_t.values.reshape(-1,1)\n",
    "hours_trans_t = kbins.fit_transform(hours_t)\n",
    "\n",
    "age_t=pd.DataFrame(age_trans_t,columns =['age'])\n",
    "fw_t=pd.DataFrame(fw_trans_t,columns =['fnlwgt'])\n",
    "edunum_t=pd.DataFrame(edunum_trans_t,columns =['educational-num'])\n",
    "cg_t=pd.DataFrame(cg_trans_t,columns =['capital-gain'])\n",
    "cl_t=pd.DataFrame(cl_trans_t,columns =['capital-loss'])\n",
    "hours_t=pd.DataFrame(hours_trans_t,columns =['hours-per-week'])\n",
    "\n",
    "\n",
    "numerical_trans_t = pd.concat([age_t,fw_t,edunum_t,cg_t,cl_t,hours_t],axis=1)\n",
    "\n",
    "xs_bnb_test = pd.concat([xs_test[categorical],numerical_trans_t],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# import the trained encoder_bnb\n",
    "import pickle\n",
    "with open(\"trained_models/encoder_bnb.pkl\", \"rb\") as f:\n",
    "    encoder_bnb = pickle.load(f)\n",
    "\n",
    "#Encode the unseen test data\n",
    "# xs_bnb_test = encoder_bnb.transform(xs_bnb_test)\n",
    "# ys_bnb_test = ys_test\n",
    "\n",
    "x_test_nb = encoder_bnb.transform(xs_bnb_test)\n",
    "y_test_nb = ys_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict the Result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Result of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=9, max_features=8, min_samples_leaf=10,\n",
      "                       min_samples_split=8)\n",
      "[0 1 0 ... 0 0 0]\n",
      "(26048,)\n",
      "[0 0 1 ... 1 0 0]\n",
      "(6513,)\n",
      "[0 0 0 ... 1 0 1]\n",
      "(16281,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     12435\n",
      "           1       0.77      0.54      0.64      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.82      0.75      0.77     16281\n",
      "weighted avg       0.85      0.85      0.84     16281\n",
      "\n",
      "ROC_AUC score: 0.7459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the decision tree\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Load model\n",
    "with open('trained_models/pruned_decision_tree.pkl', 'rb') as f:\n",
    "    decision_tree = pickle.load(f)\n",
    "\n",
    "print(decision_tree)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_tree_proba = decision_tree.predict_proba(x_train_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_tree_proba)\n",
    "# print(y_pred_tree_proba.shape)\n",
    "y_pred_tree = decision_tree.predict(x_train_tree)  # binary\n",
    "print(y_pred_tree)\n",
    "print(y_pred_tree.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_tree_proba = decision_tree.predict_proba(x_val_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_val_tree_proba)\n",
    "# print(y_pred_val_tree_proba.shape)\n",
    "y_pred_val_tree = decision_tree.predict(x_val_tree)  # binary\n",
    "print(y_pred_val_tree)\n",
    "print(y_pred_val_tree.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_tree_proba = decision_tree.predict_proba(x_test_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_test_tree_proba)\n",
    "# print(y_pred_test_tree_proba.shape)\n",
    "y_pred_test_tree = decision_tree.predict(x_test_tree)  # binary\n",
    "print(y_pred_test_tree)\n",
    "print(y_pred_test_tree.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model \n",
    "# print(classification_report(y_test_tree,y_pred_test_tree_proba > 0.5))\n",
    "# auc = roc_auc_score(y_test_tree, y_pred_test_tree_proba > 0.5)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Result of k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=16, metric='manhattan', n_neighbors=29)\n",
      "[0 1 0 ... 0 0 0]\n",
      "(26048,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "(6513,)\n",
      "[0 0 1 ... 1 0 1]\n",
      "(16281,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load k-NN model\n",
    "knn_model = joblib.load('trained_models/kNN.pkl')\n",
    "print(knn_model)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_knn_proba = knn_model.predict_proba(x_train_knn)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_knn_proba)\n",
    "# print(y_pred_knn_proba.shape)\n",
    "y_pred_knn = knn_model.predict(x_train_knn)  # binary result\n",
    "print(y_pred_knn)\n",
    "print(y_pred_knn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_knn_proba = knn_model.predict_proba(x_val_knn)[:, 1]  # probability of \">50k\"\n",
    "y_pred_val_knn = knn_model.predict(x_val_knn)  # binary result\n",
    "print(y_pred_val_knn)\n",
    "print(y_pred_val_knn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_knn_proba = knn_model.predict_proba(x_test_knn)[:, 1]  # probability of \">50k\"\n",
    "y_pred_test_knn = knn_model.predict(x_test_knn)  # binary result\n",
    "print(y_pred_test_knn)\n",
    "print(y_pred_test_knn.shape)\n",
    "\n",
    "# Evaluate the the model\n",
    "# print(classification_report(y_train_knn,y_pred_knn))\n",
    "# auc = roc_auc_score(y_train_knn,y_pred_knn)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Result of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814/814 [==============================] - 1s 986us/step\n",
      "[0 1 0 ... 0 0 0]\n",
      "(26048,)\n",
      "204/204 [==============================] - 0s 737us/step\n",
      "[0 0 1 ... 1 0 0]\n",
      "(6513,)\n",
      "509/509 [==============================] - 0s 705us/step\n",
      "[0 0 0 ... 1 0 1]\n",
      "(16281,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load neutral network model\n",
    "nn_model = keras.models.load_model('trained_models/NeuralNetwork.h5')\n",
    "# nn_model.summary()\n",
    "# print(x_train_nn)\n",
    "# print(x_train_nn.shape)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_nn_proba = nn_model.predict(x_train_nn)  # probability of \">50k\"\n",
    "y_pred_nn_proba = np.squeeze(y_pred_nn_proba)  # to 1-d array\n",
    "# print(y_pred_nn_prob)\n",
    "# print(y_pred_nn_prob.shape)\n",
    "y_pred_nn = np.where(y_pred_nn_proba > 0.5, 1, 0)  # probability to binary results\n",
    "print(y_pred_nn)\n",
    "print(y_pred_nn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_nn_proba = nn_model.predict(x_val_nn)  # probability of \">50k\"\n",
    "y_pred_val_nn_proba = np.squeeze(y_pred_val_nn_proba)  # to 1-d array\n",
    "# print(y_pred_val_nn_proba)\n",
    "# print(y_pred_val_nn_proba.shape)\n",
    "y_pred_val_nn = np.where(y_pred_val_nn_proba > 0.5, 1, 0)  # probability to binary results\n",
    "print(y_pred_val_nn)\n",
    "print(y_pred_val_nn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_nn_proba = nn_model.predict(x_test_nn)  # probability of \">50k\"\n",
    "y_pred_test_nn_proba = np.squeeze(y_pred_test_nn_proba)  # to 1-d array\n",
    "# print(y_pred_test_nn_proba)\n",
    "# print(y_pred_test_nn_proba.shape)\n",
    "y_pred_test_nn = np.where(y_pred_test_nn_proba > 0.5, 1, 0)  # probability to binary results\n",
    "print(y_pred_test_nn)\n",
    "print(y_pred_test_nn.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_train_nn,y_pred_nn))\n",
    "# auc = roc_auc_score(y_train_nn, y_pred_nn)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Result of Bayesian learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator BernoulliNB from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 0]\n",
      "(26048,)\n",
      "[0 0 1 ... 1 0 0]\n",
      "(6513,)\n",
      "[0 0 1 ... 1 0 1]\n",
      "(16281,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     12435\n",
      "           1       0.63      0.65      0.64      3846\n",
      "\n",
      "    accuracy                           0.83     16281\n",
      "   macro avg       0.76      0.76      0.76     16281\n",
      "weighted avg       0.83      0.83      0.83     16281\n",
      "\n",
      "ROC_AUC score: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# Load NB model\n",
    "nb_model = pickle.load(open('trained_models/BernoullilNaiveBayes.sav', 'rb'))\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_nb_proba = nb_model.predict_proba(x_train_nb)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_nb_proba)\n",
    "# print(y_pred_nb_proba.shape)\n",
    "y_pred_nb = nb_model.predict(x_train_nb)\n",
    "print(y_pred_nb)\n",
    "print(y_pred_nb.shape)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_nb_proba = nb_model.predict_proba(x_val_nb)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_val_nb_proba)\n",
    "# print(y_pred_val_nb_proba.shape)\n",
    "y_pred_val_nb = nb_model.predict(x_val_nb)\n",
    "print(y_pred_val_nb)\n",
    "print(y_pred_val_nb.shape)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_nb_proba = nb_model.predict_proba(x_test_nb)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_test_nb_proba)\n",
    "# print(y_pred_test_nb_proba.shape)\n",
    "y_pred_test_nb = nb_model.predict(x_test_nb)\n",
    "print(y_pred_test_nb)\n",
    "print(y_pred_test_nb.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test_nb,y_pred_test_nb))\n",
    "# auc = roc_auc_score(y_test_nb, y_pred_test_nb)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Majority Voting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Custom Esemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "class EnsembleModel():\n",
    "\n",
    "    def __init__(self, voting):\n",
    "        self.voting = voting\n",
    "        \n",
    "\n",
    "    def predict(self, predictions, weights=[]):\n",
    "        # Stack the predictions into a single array\n",
    "        predictions_stack = np.stack(predictions)  # stack prediction of base classifiers; shape: (num_of_base_models, num_of_test_instances)\n",
    "        \n",
    "        # print(predictions.shape)\n",
    "        if (self.voting == \"soft\"):\n",
    "            # Soft Voting\n",
    "            # Compute the weighted average of the predictions along the first axis (i.e., across each column)\n",
    "            if (weights == []):\n",
    "                # Default: weights are equal\n",
    "                soft_pred_prob = np.average(predictions_stack, axis=0)\n",
    "            else:\n",
    "                # Use passing weights\n",
    "                soft_pred_prob = np.average(predictions_stack, axis=0, weights=weights)\n",
    "\n",
    "            soft_pred = np.where(soft_pred_prob > 0.5, 1, 0)  # probability to 0/1\n",
    "            return soft_pred\n",
    "        else:\n",
    "            # Hard Voting\n",
    "            # Compute the mode of the predictions along the first axis (i.e., across each column)\n",
    "            mode_pred = mode(predictions_stack, axis=0).mode\n",
    "            mode_pred = np.transpose(mode_pred) \n",
    "            mode_pred = np.squeeze(mode_pred)\n",
    "            # print(mode_pred)\n",
    "            # print(mode_pred.shape)\n",
    "            return mode_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hard Voting VS. Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048,)\n",
      "(6513,)\n",
      "(16281,)\n"
     ]
    }
   ],
   "source": [
    "# prepare target values\n",
    "y_train = y_train_tree\n",
    "y_val = y_val_tree\n",
    "y_test = y_test_tree\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/nxhg4vsx36x27z5gtvc6ylk00000gn/T/ipykernel_8386/2289312344.py:29: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_pred = mode(predictions_stack, axis=0).mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score: 0.7450\n",
      "Validation ROC_AUC score: 0.7321\n"
     ]
    }
   ],
   "source": [
    "predictions_train = [y_pred_tree, y_pred_knn, y_pred_nn, y_pred_nb]  # binary predictions for training data\n",
    "predictions_val = [y_pred_val_tree, y_pred_val_knn, y_pred_val_nn, y_pred_val_nb]  # binary predictions for validation data\n",
    "predictions_test = [y_pred_test_tree, y_pred_test_knn, y_pred_test_nn, y_pred_test_nb]  # binary predictions for testing data\n",
    "\n",
    "e_hard = EnsembleModel(\"hard\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "hard_pred = e_hard.predict(predictions_train)\n",
    "# print(hard_pred)\n",
    "# print(hard_pred.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "hard_pred_val = e_hard.predict(predictions_val)\n",
    "# print(hard_pred_val)\n",
    "# print(hard_pred_val.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,hard_pred))\n",
    "auc = roc_auc_score(y_train, hard_pred)  # ROC score\n",
    "print('Training ROC_AUC score: {:.4f}'.format(auc))\n",
    "\n",
    "auc = roc_auc_score(y_val, hard_pred_val)  # ROC score\n",
    "print('Validation ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score: 0.7857\n",
      "Validation ROC_AUC score: 0.7321\n"
     ]
    }
   ],
   "source": [
    "predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "predictions_test = [y_pred_test_tree_proba, y_pred_test_knn_proba, y_pred_test_nn_proba, y_pred_test_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "# default weights = [1, 1, 1, 1]\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred = e_soft.predict(predictions_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val = e_soft.predict(predictions_val)\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "auc = roc_auc_score(y_train, soft_pred)  # ROC score\n",
    "print('Training ROC_AUC score: {:.4f}'.format(auc))\n",
    "auc = roc_auc_score(y_val, hard_pred_val)  # ROC score\n",
    "print('Validation ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation ROC_AUC score of them are the same, but the training ROC_AUC score is higher on the soft voting model. So it is considered better than the hard voting model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluation\n",
    "We want to know how them perform on unseen data, so we evaluate both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/nxhg4vsx36x27z5gtvc6ylk00000gn/T/ipykernel_8386/2289312344.py:29: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_pred = mode(predictions_stack, axis=0).mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     12435\n",
      "           1       0.78      0.52      0.62      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.82      0.74      0.77     16281\n",
      "weighted avg       0.84      0.85      0.84     16281\n",
      "\n",
      "Hard voting ROC_AUC score: 0.7366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     12435\n",
      "           1       0.73      0.61      0.66      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.81      0.77      0.79     16281\n",
      "weighted avg       0.85      0.85      0.85     16281\n",
      "\n",
      "Soft voting ROC_AUC score: 0.7705\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "predictions_test = [y_pred_test_tree, y_pred_test_knn, y_pred_test_nn, y_pred_test_nb]  # binary predictions for testing data\n",
    "hard_pred_test = e_hard.predict(predictions_test)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions_test = [y_pred_test_tree_proba, y_pred_test_knn_proba, y_pred_test_nn_proba, y_pred_test_nb_proba]  # probability predictions for validation data\n",
    "soft_pred_test = e_soft.predict(predictions_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, hard_pred_test))\n",
    "auc = roc_auc_score(y_test, hard_pred_test)  # ROC score\n",
    "print('Hard voting ROC_AUC score: {:.4f}'.format(auc))\n",
    "\n",
    "print(classification_report(y_test,soft_pred_test))\n",
    "auc = roc_auc_score(y_test, soft_pred_test)  # ROC score\n",
    "print('Soft voting ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyper-parameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Test domination of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score 1 (dt): 0.7870\n",
      "Training ROC_AUC score 2 (knn): 0.7759\n",
      "Training ROC_AUC score 3 (nn): 0.7726\n",
      "Training ROC_AUC score 4 (bnb): 0.7703\n",
      "Validation ROC_AUC score 1 (dt): 0.7937\n",
      "Validation ROC_AUC score 2 (knn): 0.6381\n",
      "Validation ROC_AUC score 3 (nn): 0.7737\n",
      "Validation ROC_AUC score 4 (bnb): 0.7748\n"
     ]
    }
   ],
   "source": [
    "predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "predictions_test = [y_pred_test_tree_proba, y_pred_test_knn_proba, y_pred_test_nn_proba, y_pred_test_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "weights1 = [0.7, 0.1, 0.1, 0.1]  # decision tree dominate\n",
    "weights2 = [0.1, 0.7, 0.1, 0.1]  # knn deminate\n",
    "weights3 = [0.1, 0.1, 0.7, 0.1]  # neutral network dominate\n",
    "weights4 = [0.1, 0.1, 0.1, 0.7]  # Bernoulli NB\n",
    "\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred_1 = e_soft.predict(predictions_train, weights1)\n",
    "soft_pred_2 = e_soft.predict(predictions_train, weights2)\n",
    "soft_pred_3 = e_soft.predict(predictions_train, weights3)\n",
    "soft_pred_4 = e_soft.predict(predictions_train, weights4)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val_1 = e_soft.predict(predictions_val, weights1)\n",
    "soft_pred_val_2 = e_soft.predict(predictions_val, weights2)\n",
    "soft_pred_val_3 = e_soft.predict(predictions_val, weights3)\n",
    "soft_pred_val_4 = e_soft.predict(predictions_val, weights4)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "print('Training ROC_AUC score 1 (dt): {:.4f}'.format(roc_auc_score(y_train, soft_pred_1)))\n",
    "print('Training ROC_AUC score 2 (knn): {:.4f}'.format(roc_auc_score(y_train, soft_pred_2)))\n",
    "print('Training ROC_AUC score 3 (nn): {:.4f}'.format(roc_auc_score(y_train, soft_pred_3)))\n",
    "print('Training ROC_AUC score 4 (bnb): {:.4f}'.format(roc_auc_score(y_train, soft_pred_4)))\n",
    "\n",
    "print('Validation ROC_AUC score 1 (dt): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_1)))\n",
    "print('Validation ROC_AUC score 2 (knn): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_2)))\n",
    "print('Validation ROC_AUC score 3 (nn): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_3)))\n",
    "print('Validation ROC_AUC score 4 (bnb): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree dominate model give the best result both on training set and validation set, so it is consdiered to be the best model.\n",
    "\n",
    "The knn perform well on the training set, but bad on the validation set, so it is probably overfit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Attemp improving the preformance\n",
    "Now that we know when the decision tree is dominate, the performance is better. Next, we want to try lifting and decrising its weight, and see if we can further improve."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Increasing weights of decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score 1 (0.7): 0.7870\n",
      "Training ROC_AUC score 2 (0.8): 0.7868\n",
      "Training ROC_AUC score 3 (0.9): 0.7854\n",
      "Training ROC_AUC score 4 (1.0): 0.7572\n",
      "Validation ROC_AUC score 1 (0.7): 0.7937\n",
      "Validation ROC_AUC score 2 (0.8): 0.7934\n",
      "Validation ROC_AUC score 3 (0.9): 0.7924\n",
      "Validation ROC_AUC score 4 (1.0): 0.7663\n"
     ]
    }
   ],
   "source": [
    "# predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "# predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "weights1 = [0.7, 0.1, 0.1, 0.1]  # decision tree dominate\n",
    "weights2 = [0.8, 0.067, 0.067, 0.066]  # decision tree dominate\n",
    "weights3 = [0.9, 0.034, 0.034, 0.034]  # decision tree dominate\n",
    "weights4 = [1, 0, 0, 0]  # decision tree dominate\n",
    "\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred_1 = e_soft.predict(predictions_train, weights1)\n",
    "soft_pred_2 = e_soft.predict(predictions_train, weights2)\n",
    "soft_pred_3 = e_soft.predict(predictions_train, weights3)\n",
    "soft_pred_4 = e_soft.predict(predictions_train, weights4)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val_1 = e_soft.predict(predictions_val, weights1)\n",
    "soft_pred_val_2 = e_soft.predict(predictions_val, weights2)\n",
    "soft_pred_val_3 = e_soft.predict(predictions_val, weights3)\n",
    "soft_pred_val_4 = e_soft.predict(predictions_val, weights4)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "print('Training ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_train, soft_pred_1)))\n",
    "print('Training ROC_AUC score 2 (0.8): {:.4f}'.format(roc_auc_score(y_train, soft_pred_2)))\n",
    "print('Training ROC_AUC score 3 (0.9): {:.4f}'.format(roc_auc_score(y_train, soft_pred_3)))\n",
    "print('Training ROC_AUC score 4 (1.0): {:.4f}'.format(roc_auc_score(y_train, soft_pred_4)))\n",
    "\n",
    "print('Validation ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_1)))\n",
    "print('Validation ROC_AUC score 2 (0.8): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_2)))\n",
    "print('Validation ROC_AUC score 3 (0.9): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_3)))\n",
    "print('Validation ROC_AUC score 4 (1.0): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We foudout that increasing the weights of the decision tree doesn't help, so next we will try to decreaing its weights while keep it dominate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Decreasing weights of decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score 1 (0.7): 0.7870\n",
      "Training ROC_AUC score 2 (0.6): 0.7840\n",
      "Training ROC_AUC score 3 (0.5): 0.7853\n",
      "Training ROC_AUC score 4 (0.4): 0.7865\n",
      "Validation ROC_AUC score 1 (0.7): 0.7937\n",
      "Validation ROC_AUC score 2 (0.6): 0.7897\n",
      "Validation ROC_AUC score 3 (0.5): 0.7919\n",
      "Validation ROC_AUC score 4 (0.4): 0.7866\n"
     ]
    }
   ],
   "source": [
    "# predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "# predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "weights1 = [0.7, 0.1, 0.1, 0.1]  # decision tree dominate\n",
    "weights2 = [0.6, 0.013, 0.013, 0.013]  # decision tree dominate\n",
    "weights3 = [0.5, 0.017, 0.017, 0.017]  # decision tree dominate\n",
    "weights4 = [0.4, 0.2, 0.2, 0.2 ]  # decision tree dominate\n",
    "\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred_1 = e_soft.predict(predictions_train, weights1)\n",
    "soft_pred_2 = e_soft.predict(predictions_train, weights2)\n",
    "soft_pred_3 = e_soft.predict(predictions_train, weights3)\n",
    "soft_pred_4 = e_soft.predict(predictions_train, weights4)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val_1 = e_soft.predict(predictions_val, weights1)\n",
    "soft_pred_val_2 = e_soft.predict(predictions_val, weights2)\n",
    "soft_pred_val_3 = e_soft.predict(predictions_val, weights3)\n",
    "soft_pred_val_4 = e_soft.predict(predictions_val, weights4)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "print('Training ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_train, soft_pred_1)))\n",
    "print('Training ROC_AUC score 2 (0.6): {:.4f}'.format(roc_auc_score(y_train, soft_pred_2)))\n",
    "print('Training ROC_AUC score 3 (0.5): {:.4f}'.format(roc_auc_score(y_train, soft_pred_3)))\n",
    "print('Training ROC_AUC score 4 (0.4): {:.4f}'.format(roc_auc_score(y_train, soft_pred_4)))\n",
    "\n",
    "print('Validation ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_1)))\n",
    "print('Validation ROC_AUC score 2 (0.6): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_2)))\n",
    "print('Validation ROC_AUC score 3 (0.5): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_3)))\n",
    "print('Validation ROC_AUC score 4 (0.4): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, when the weights of the decision tree model is 0.7, and even weights (0.1) for other models, the performance is the best."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     12435\n",
      "           1       0.75      0.61      0.67      3846\n",
      "\n",
      "    accuracy                           0.86     16281\n",
      "   macro avg       0.82      0.77      0.79     16281\n",
      "weighted avg       0.85      0.86      0.85     16281\n",
      "\n",
      "Soft voting ROC_AUC score: 0.7710\n"
     ]
    }
   ],
   "source": [
    "best_weights = [0.7, 0.1, 0.1, 0.1]  # decision tree dominate\n",
    "\n",
    "model_ensemble = EnsembleModel(\"soft\")  # soft voting model\n",
    "\n",
    "# Make predictions on the testing data\n",
    "soft_pred = model_ensemble.predict(predictions_test, best_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test,soft_pred))\n",
    "auc = roc_auc_score(y_test, soft_pred)  # ROC score\n",
    "print('Soft voting ROC_AUC score: {:.4f}'.format(auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
