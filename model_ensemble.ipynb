{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensemble\n",
    "In this task, we are going to implement a model ensemble using stacking. It stacks well-trained models from previous tasks through a voting mechanism. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect and Explore the Data\n",
    "Take a look at these data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "(16281, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"data/data_train.csv\")\n",
    "data_test = pd.read_csv(\"data/data_test.csv\")\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  educational_num  \\\n",
       "0   39         State-gov   77516  Bachelors               13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors               13   \n",
       "2   38           Private  215646    HS-grad                9   \n",
       "3   53           Private  234721       11th                7   \n",
       "4   28           Private  338409  Bachelors               13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States       0  \n",
       "1             0             0              13  United-States       0  \n",
       "2             0             0              40  United-States       0  \n",
       "3             0             0              40  United-States       0  \n",
       "4             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational_num  capital-gain  \\\n",
       "count  32561.000000  3.256100e+04     32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05        10.080679   1077.648844   \n",
       "std       13.640433  1.055500e+05         2.572720   7385.292085   \n",
       "min       17.000000  1.228500e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05        12.000000      0.000000   \n",
       "max       90.000000  1.484705e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  32561.000000    32561.000000  32561.000000  \n",
       "mean      87.303830       40.437456      0.240810  \n",
       "std      402.960219       12.347429      0.427581  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     4356.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational_num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18    Private  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4     Prof-specialty    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  income  \n",
       "0              40  United-States       0  \n",
       "1              50  United-States       0  \n",
       "2              40  United-States       1  \n",
       "3              40  United-States       1  \n",
       "4              30  United-States       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16281.000000</td>\n",
       "      <td>1.628100e+04</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "      <td>16281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.767459</td>\n",
       "      <td>1.894357e+05</td>\n",
       "      <td>10.072907</td>\n",
       "      <td>1081.905104</td>\n",
       "      <td>87.899269</td>\n",
       "      <td>40.392236</td>\n",
       "      <td>0.236226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.849187</td>\n",
       "      <td>1.057149e+05</td>\n",
       "      <td>2.567545</td>\n",
       "      <td>7583.935968</td>\n",
       "      <td>403.105286</td>\n",
       "      <td>12.479332</td>\n",
       "      <td>0.424776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.167360e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.778310e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.383840e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational_num  capital-gain  \\\n",
       "count  16281.000000  1.628100e+04     16281.000000  16281.000000   \n",
       "mean      38.767459  1.894357e+05        10.072907   1081.905104   \n",
       "std       13.849187  1.057149e+05         2.567545   7583.935968   \n",
       "min       17.000000  1.349200e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.167360e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.778310e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.383840e+05        12.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week        income  \n",
       "count  16281.000000    16281.000000  16281.000000  \n",
       "mean      87.899269       40.392236      0.236226  \n",
       "std      403.105286       12.479332      0.424776  \n",
       "min        0.000000        1.000000      0.000000  \n",
       "25%        0.000000       40.000000      0.000000  \n",
       "50%        0.000000       40.000000      0.000000  \n",
       "75%        0.000000       45.000000      0.000000  \n",
       "max     3770.000000       99.000000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "workclass          object\n",
      "fnlwgt              int64\n",
      "education          object\n",
      "educational_num     int64\n",
      "marital-status     object\n",
      "occupation         object\n",
      "relationship       object\n",
      "race               object\n",
      "gender             object\n",
      "capital-gain        int64\n",
      "capital-loss        int64\n",
      "hours-per-week      int64\n",
      "native-country     object\n",
      "income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "workclass          object\n",
      "fnlwgt              int64\n",
      "education          object\n",
      "educational_num     int64\n",
      "marital-status     object\n",
      "occupation         object\n",
      "relationship       object\n",
      "race               object\n",
      "gender             object\n",
      "capital-gain        int64\n",
      "capital-loss        int64\n",
      "hours-per-week      int64\n",
      "native-country     object\n",
      "income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_test.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "As everyone might have different preprocess actions towards the training dataset, it is necessary to perform corresponding preprocess actions to the testing set and then it can be used to test different models. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Prepare train and validation data for the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data_train['workclass'] = encoder.fit_transform(data_train['workclass'])\n",
    "data_train['marital-status'] = encoder.fit_transform(\n",
    "    data_train['marital-status'])\n",
    "data_train['occupation'] = encoder.fit_transform(data_train['occupation'])\n",
    "data_train['relationship'] = encoder.fit_transform(data_train['relationship'])\n",
    "data_train['race'] = encoder.fit_transform(data_train['race'])\n",
    "data_train['gender'] = encoder.fit_transform(data_train['gender'])\n",
    "data_train['native-country'] = encoder.fit_transform(\n",
    "    data_train['native-country'])\n",
    "\n",
    "# Preprocessed test set for decision tree\n",
    "x_train = data_train[feature_names]\n",
    "y_train = data_train['income']\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_tree, x_val_tree, y_train_tree, y_val_tree = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(x_train_tree.shape)\n",
    "# print(x_val_tree.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Prepare test data for the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "feature_names = ['age', 'workclass', 'fnlwgt', 'educational_num', 'marital-status', 'occupation', 'relationship',\n",
    "                 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data_test['workclass'] = encoder.fit_transform(data_test['workclass'])\n",
    "data_test['marital-status'] = encoder.fit_transform(\n",
    "    data_test['marital-status'])\n",
    "data_test['occupation'] = encoder.fit_transform(data_test['occupation'])\n",
    "data_test['relationship'] = encoder.fit_transform(data_test['relationship'])\n",
    "data_test['race'] = encoder.fit_transform(data_test['race'])\n",
    "data_test['gender'] = encoder.fit_transform(data_test['gender'])\n",
    "data_test['native-country'] = encoder.fit_transform(\n",
    "    data_test['native-country'])\n",
    "\n",
    "# Preprocessed test set for decision tree\n",
    "x_test_tree = data_test[feature_names]\n",
    "y_test_tree = data_test['income']\n",
    "\n",
    "# Preprocessed test set\n",
    "# print(x_test_tree)\n",
    "# print(y_test_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 K-NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Prepare train and validation data for the k-NN\n",
    "Load the data and encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40875606 -1.88422155  0.08005085 ... -0.21799808  0.77946024\n",
      "   0.26333357]\n",
      " [-0.1888573  -0.0841701  -0.98165286 ...  4.45716784  0.77946024\n",
      "   0.26333357]\n",
      " [ 1.42373357  1.71588136  0.126197   ... -0.21799808 -0.03151042\n",
      "   0.26333357]\n",
      " ...\n",
      " [-1.50824984 -0.0841701   0.25206312 ... -0.21799808 -1.65345173\n",
      "   0.26333357]\n",
      " [ 0.83733689  1.71588136 -1.28762772 ... -0.21799808  3.53676046\n",
      "   0.26333357]\n",
      " [-0.33545648  0.81585563 -0.59020877 ... -0.21799808  1.59043089\n",
      "   0.26333357]]\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "\n",
    "# transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_train\n",
    "le = LabelEncoder()\n",
    "test_knn = []\n",
    "for col in cat_columns:\n",
    "    data_train[col] = le.fit_transform(data_train[col])\n",
    "\n",
    "# Split the test set\n",
    "x_train = data_train.drop(columns =['income'])\n",
    "y_train = data_train['income']\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_knn, x_val_knn, y_train_knn, y_val_knn = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(x_train_knn.shape)\n",
    "# print(x_val_knn.shape)\n",
    "\n",
    "#Standard Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train_knn = preprocessing.StandardScaler().fit(x_train_knn).transform(x_train_knn.astype(float))\n",
    "print(x_train_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Prepare test data for the k-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "\n",
    "# transformation \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Select the categorical columns to encode\n",
    "cat_columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native-country\"]\n",
    "\n",
    "# Encode categorical columns using Label Encoding for data_test\n",
    "le = LabelEncoder()\n",
    "test_knn = []\n",
    "for col in cat_columns:\n",
    "    data_test[col] = le.fit_transform(data_test[col])\n",
    "\n",
    "# Split the test set\n",
    "x_test_knn = data_test.drop(columns =['income'])\n",
    "y_test_knn = data_test['income']\n",
    "\n",
    "# Print the first 5 rows of the transformed dataset\n",
    "# print(x_test_knn.head())\n",
    "# print(y_test_knn.head())\n",
    "\n",
    "#Standard Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_test_knn = preprocessing.StandardScaler().fit(x_test_knn).transform(x_test_knn.astype(float))\n",
    "# print(x_test_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Prepare train and validation data for the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 14)\n",
      "(6513, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load test data\n",
    "data_train = pd.read_csv('data/data_train.csv', header=0)\n",
    "\n",
    "# feature transformation\n",
    "for col in data_train:\n",
    "    if data_train[col].dtype == 'object':\n",
    "        data_train[col] = encoder.fit_transform(data_train[col].astype(str))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "for col in data_train.columns:\n",
    "    data_train[col] = scaler.fit_transform(data_train[[col]])\n",
    "\n",
    "x_train = data_train.iloc[:, :-1]\n",
    "y_train = data_train.iloc[:, -1]\n",
    "# print(x_test_nn)\n",
    "# print(y_test_nn)\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_nn, x_val_nn, y_train_nn, y_val_nn = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train_nn.shape)\n",
    "print(x_val_nn.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Prepare test data for the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load test data\n",
    "data_test = pd.read_csv('data/data_test.csv', header=0)\n",
    "\n",
    "# feature transformation\n",
    "for col in data_test:\n",
    "    if data_test[col].dtype == 'object':\n",
    "        data_test[col] = encoder.fit_transform(data_test[col].astype(str))\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "for col in data_test.columns:\n",
    "    data_test[col] = scaler.fit_transform(data_test[[col]])\n",
    "\n",
    "x_test_nn = data_test.iloc[:, :-1]\n",
    "y_test_nn = data_test.iloc[:, -1]\n",
    "# print(x_test_nn)\n",
    "# print(y_test_nn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bayesian Leanring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Prepare train data and validation for the Bayesian learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the tain data\n",
    "import pandas as pd\n",
    "data_test = pd.read_csv('data/data_train.csv')\n",
    "data_test = data_test.reset_index()\n",
    "xs_test = data_test.drop(['income'], axis=1)\n",
    "ys_test = data_test['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
      "There are 7 numerical variables\n",
      "\n",
      "The numerical variables are :\n",
      "\n",
      " ['index', 'age', 'fnlwgt', 'educational_num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "#Store all the categorical features\n",
    "categorical = [var for var in xs_test.columns if xs_test[var].dtype=='O']\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "#Store all the numerical features\n",
    "numerical = [var for var in xs_test.columns if xs_test[var].dtype!='O']\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "print('The numerical variables are :\\n\\n', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Discretization the numerical features##\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#Age\n",
    "age_t = xs_test['age']\n",
    "age_t=age_t.values.reshape(-1,1)\n",
    "age_trans_t = kbins.fit_transform(age_t)\n",
    "\n",
    "#Final weight\n",
    "fw_t = xs_test['fnlwgt']\n",
    "fw_t=fw_t.values.reshape(-1,1)\n",
    "fw_trans_t = kbins.fit_transform(fw_t)\n",
    "\n",
    "#educational_num\n",
    "edunum_t = xs_test['educational_num']\n",
    "edunum_t=edunum_t.values.reshape(-1,1)\n",
    "edunum_trans_t = kbins.fit_transform(edunum_t)\n",
    "\n",
    "#capital gain\n",
    "cg_t = xs_test['capital-gain']\n",
    "cg_t=cg_t.values.reshape(-1,1)\n",
    "cg_trans_t = kbins.fit_transform(cg_t)\n",
    "\n",
    "#capital loss\n",
    "cl_t = xs_test['capital-loss']\n",
    "cl_t=cl_t.values.reshape(-1,1)\n",
    "cl_trans_t = kbins.fit_transform(cl_t)\n",
    "\n",
    "#hours-per-week\n",
    "hours_t = xs_test['hours-per-week']\n",
    "hours_t=hours_t.values.reshape(-1,1)\n",
    "hours_trans_t = kbins.fit_transform(hours_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_t=pd.DataFrame(age_trans_t,columns =['age'])\n",
    "fw_t=pd.DataFrame(fw_trans_t,columns =['fnlwgt'])\n",
    "edunum_t=pd.DataFrame(edunum_trans_t,columns =['educational-num'])\n",
    "cg_t=pd.DataFrame(cg_trans_t,columns =['capital-gain'])\n",
    "cl_t=pd.DataFrame(cl_trans_t,columns =['capital-loss'])\n",
    "hours_t=pd.DataFrame(hours_trans_t,columns =['hours-per-week'])\n",
    "\n",
    "\n",
    "numerical_trans_t = pd.concat([age_t,fw_t,edunum_t,cg_t,cl_t,hours_t],axis=1)\n",
    "\n",
    "xs_bnb_test = pd.concat([xs_test[categorical],numerical_trans_t],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 154)\n",
      "(6513, 154)\n"
     ]
    }
   ],
   "source": [
    "#install encoder library\n",
    "# !pip install category_encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "#import the trained encoder_bnb\n",
    "import pickle\n",
    "with open(\"output/Bayes_Learning/encoder_bnb.pkl\", \"rb\") as f:\n",
    "    encoder_bnb = pickle.load(f)\n",
    "\n",
    "#Encode the unseen test data\n",
    "# xs_bnb_test = encoder_bnb.transform(xs_bnb_test)\n",
    "# ys_bnb_test = ys_test\n",
    "\n",
    "x_train = encoder_bnb.transform(xs_bnb_test)\n",
    "y_train = ys_test\n",
    "\n",
    "# Spliting the training set and validation set by 20%\n",
    "x_train_nb, x_val_nb, y_train_nb, y_val_nb = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train_nb.shape)\n",
    "print(x_val_nb.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Prepare test for the Bayesian learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
      "There are 7 numerical variables\n",
      "\n",
      "The numerical variables are :\n",
      "\n",
      " ['index', 'age', 'fnlwgt', 'educational_num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "#Importing the testing data\n",
    "import pandas as pd\n",
    "data_test = pd.read_csv('data/data_test.csv')\n",
    "data_test = data_test.reset_index()\n",
    "xs_test = data_test.drop(['income'], axis=1)\n",
    "ys_test = data_test['income']\n",
    "\n",
    "#Store all the categorical features\n",
    "categorical = [var for var in xs_test.columns if xs_test[var].dtype=='O']\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "#Store all the numerical features\n",
    "numerical = [var for var in xs_test.columns if xs_test[var].dtype!='O']\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "print('The numerical variables are :\\n\\n', numerical)\n",
    "\n",
    "# Discretization the numerical features##\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#Age\n",
    "age_t = xs_test['age']\n",
    "age_t=age_t.values.reshape(-1,1)\n",
    "age_trans_t = kbins.fit_transform(age_t)\n",
    "\n",
    "#Final weight\n",
    "fw_t = xs_test['fnlwgt']\n",
    "fw_t=fw_t.values.reshape(-1,1)\n",
    "fw_trans_t = kbins.fit_transform(fw_t)\n",
    "\n",
    "#educational_num\n",
    "edunum_t = xs_test['educational_num']\n",
    "edunum_t=edunum_t.values.reshape(-1,1)\n",
    "edunum_trans_t = kbins.fit_transform(edunum_t)\n",
    "\n",
    "#capital gain\n",
    "cg_t = xs_test['capital-gain']\n",
    "cg_t=cg_t.values.reshape(-1,1)\n",
    "cg_trans_t = kbins.fit_transform(cg_t)\n",
    "\n",
    "#capital loss\n",
    "cl_t = xs_test['capital-loss']\n",
    "cl_t=cl_t.values.reshape(-1,1)\n",
    "cl_trans_t = kbins.fit_transform(cl_t)\n",
    "\n",
    "#hours-per-week\n",
    "hours_t = xs_test['hours-per-week']\n",
    "hours_t=hours_t.values.reshape(-1,1)\n",
    "hours_trans_t = kbins.fit_transform(hours_t)\n",
    "\n",
    "age_t=pd.DataFrame(age_trans_t,columns =['age'])\n",
    "fw_t=pd.DataFrame(fw_trans_t,columns =['fnlwgt'])\n",
    "edunum_t=pd.DataFrame(edunum_trans_t,columns =['educational-num'])\n",
    "cg_t=pd.DataFrame(cg_trans_t,columns =['capital-gain'])\n",
    "cl_t=pd.DataFrame(cl_trans_t,columns =['capital-loss'])\n",
    "hours_t=pd.DataFrame(hours_trans_t,columns =['hours-per-week'])\n",
    "\n",
    "\n",
    "numerical_trans_t = pd.concat([age_t,fw_t,edunum_t,cg_t,cl_t,hours_t],axis=1)\n",
    "\n",
    "xs_bnb_test = pd.concat([xs_test[categorical],numerical_trans_t],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# import the trained encoder_bnb\n",
    "import pickle\n",
    "with open(\"output/Bayes_Learning/encoder_bnb.pkl\", \"rb\") as f:\n",
    "    encoder_bnb = pickle.load(f)\n",
    "\n",
    "#Encode the unseen test data\n",
    "# xs_bnb_test = encoder_bnb.transform(xs_bnb_test)\n",
    "# ys_bnb_test = ys_test\n",
    "\n",
    "x_test_nb = encoder_bnb.transform(xs_bnb_test)\n",
    "y_test_nb = ys_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict the Result\n",
    "Since the features of training data used by our base models are different, in other words, they have different preprocessing procedures, the features of the testing data used to test base models are also different. That means a simple VotingClassifier can not be used. \n",
    "\n",
    "To address this problem, we implemented the necessary functionalities manually. The first step is to predict the results of all models for later usage (voting). Then we built a custom voting model class called EsembleModel. Not like VotingClassifier takes classifiers as input when initializing, it takes predictions we made in this section as input. Turn to section 4 to see more details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Result of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=9, max_features=8, min_samples_leaf=10,\n",
      "                       min_samples_split=8)\n",
      "[0 0 0 ... 0 0 0]\n",
      "(26048,)\n",
      "[0 0 1 ... 1 0 0]\n",
      "(6513,)\n",
      "[0 0 0 ... 1 0 1]\n",
      "(16281,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the decision tree\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Load model\n",
    "with open('output/dt/pruned_decision_tree.pkl', 'rb') as f:\n",
    "    decision_tree = pickle.load(f)\n",
    "\n",
    "print(decision_tree)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_tree_proba = decision_tree.predict_proba(x_train_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_tree_proba)\n",
    "# print(y_pred_tree_proba.shape)\n",
    "y_pred_tree = decision_tree.predict(x_train_tree)  # binary\n",
    "print(y_pred_tree)\n",
    "print(y_pred_tree.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_tree_proba = decision_tree.predict_proba(x_val_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_val_tree_proba)\n",
    "# print(y_pred_val_tree_proba.shape)\n",
    "y_pred_val_tree = decision_tree.predict(x_val_tree)  # binary\n",
    "print(y_pred_val_tree)\n",
    "print(y_pred_val_tree.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_tree_proba = decision_tree.predict_proba(x_test_tree)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_test_tree_proba)\n",
    "# print(y_pred_test_tree_proba.shape)\n",
    "y_pred_test_tree = decision_tree.predict(x_test_tree)  # binary\n",
    "print(y_pred_test_tree)\n",
    "print(y_pred_test_tree.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model \n",
    "# print(classification_report(y_test_tree,y_pred_test_tree_proba > 0.5))\n",
    "# auc = roc_auc_score(y_test_tree, y_pred_test_tree_proba > 0.5)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Result of k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=16, metric='manhattan', n_neighbors=29)\n",
      "[0 1 0 ... 0 0 0]\n",
      "(26048,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "(6513,)\n",
      "[0 0 1 ... 1 0 1]\n",
      "(16281,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import time\n",
    "\n",
    "# Load k-NN model\n",
    "knn_model = joblib.load('output/knn/kNN.pkl')\n",
    "# joblib.dump(knn_model, 'output/knn/kNN.pkl')\n",
    "print(knn_model)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_knn_proba = knn_model.predict_proba(x_train_knn)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_knn_proba)\n",
    "# print(y_pred_knn_proba.shape)\n",
    "y_pred_knn = knn_model.predict(x_train_knn)  # binary result\n",
    "print(y_pred_knn)\n",
    "print(y_pred_knn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_knn_proba = knn_model.predict_proba(x_val_knn)[:, 1]  # probability of \">50k\"\n",
    "y_pred_val_knn = knn_model.predict(x_val_knn)  # binary result\n",
    "print(y_pred_val_knn)\n",
    "print(y_pred_val_knn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_knn_proba = knn_model.predict_proba(x_test_knn)[:, 1]  # probability of \">50k\"\n",
    "y_pred_test_knn = knn_model.predict(x_test_knn)  # binary result\n",
    "print(y_pred_test_knn)\n",
    "print(y_pred_test_knn.shape)\n",
    "\n",
    "# Evaluate the the model\n",
    "# print(classification_report(y_train_knn,y_pred_knn))\n",
    "# auc = roc_auc_score(y_train_knn,y_pred_knn)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Result of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 01:26:03.028329: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " dense_15 (Dense)            (None, 224)               3360      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 224)              896       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 224)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               28800     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 192)               6336      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 192)              768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 193       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,121\n",
      "Trainable params: 43,969\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "814/814 [==============================] - 1s 662us/step\n",
      "[0 1 0 ... 0 0 0]\n",
      "(26048,)\n",
      "204/204 [==============================] - 0s 749us/step\n",
      "[0 0 1 ... 1 0 0]\n",
      "(6513,)\n",
      "509/509 [==============================] - 0s 667us/step\n",
      "[0 0 0 ... 1 1 1]\n",
      "(16281,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load neutral network model\n",
    "nn_model = keras.models.load_model('output/NeuralNetwork/NeuralNetwork.h5')\n",
    "nn_model.summary()\n",
    "# print(x_train_nn)\n",
    "# print(x_train_nn.shape)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_nn_proba = nn_model.predict(x_train_nn)  # probability of \">50k\"\n",
    "y_pred_nn_proba = np.squeeze(y_pred_nn_proba)  # to 1-d array\n",
    "# print(y_pred_nn_prob)\n",
    "# print(y_pred_nn_prob.shape)\n",
    "y_pred_nn = np.where(y_pred_nn_proba > 0.5, 1, 0)  # probability to binary results\n",
    "print(y_pred_nn)\n",
    "print(y_pred_nn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_nn_proba = nn_model.predict(x_val_nn)  # probability of \">50k\"\n",
    "y_pred_val_nn_proba = np.squeeze(y_pred_val_nn_proba)  # to 1-d array\n",
    "# print(y_pred_val_nn_proba)\n",
    "# print(y_pred_val_nn_proba.shape)\n",
    "y_pred_val_nn = np.where(y_pred_val_nn_proba > 0.5, 1, 0)  # probability to binary results\n",
    "print(y_pred_val_nn)\n",
    "print(y_pred_val_nn.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_nn_proba = nn_model.predict(x_test_nn)  # probability of \">50k\"\n",
    "y_pred_test_nn_proba = np.squeeze(y_pred_test_nn_proba)  # to 1-d array\n",
    "# print(y_pred_test_nn_proba)\n",
    "# print(y_pred_test_nn_proba.shape)\n",
    "y_pred_test_nn = np.where(y_pred_test_nn_proba > 0.5, 1, 0)  # probability to binary results\n",
    "print(y_pred_test_nn)\n",
    "print(y_pred_test_nn.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_train_nn,y_pred_nn))\n",
    "# auc = roc_auc_score(y_train_nn, y_pred_nn)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Result of Bayesian learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 0]\n",
      "(26048,)\n",
      "[0 0 1 ... 1 0 0]\n",
      "(6513,)\n",
      "[0 0 1 ... 1 0 1]\n",
      "(16281,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoe/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator BernoulliNB from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load NB model\n",
    "nb_model = pickle.load(open('output/Bayes_Learning/BernoullilNaiveBayes.sav', 'rb'))\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_nb_proba = nb_model.predict_proba(x_train_nb)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_nb_proba)\n",
    "# print(y_pred_nb_proba.shape)\n",
    "y_pred_nb = nb_model.predict(x_train_nb)\n",
    "print(y_pred_nb)\n",
    "print(y_pred_nb.shape)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val_nb_proba = nb_model.predict_proba(x_val_nb)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_val_nb_proba)\n",
    "# print(y_pred_val_nb_proba.shape)\n",
    "y_pred_val_nb = nb_model.predict(x_val_nb)\n",
    "print(y_pred_val_nb)\n",
    "print(y_pred_val_nb.shape)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test_nb_proba = nb_model.predict_proba(x_test_nb)[:, 1]  # probability of \">50k\"\n",
    "# print(y_pred_test_nb_proba)\n",
    "# print(y_pred_test_nb_proba.shape)\n",
    "y_pred_test_nb = nb_model.predict(x_test_nb)\n",
    "print(y_pred_test_nb)\n",
    "print(y_pred_test_nb.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test_nb,y_pred_test_nb))\n",
    "# auc = roc_auc_score(y_test_nb, y_pred_test_nb)  # ROC score\n",
    "# print('ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Majority Voting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we built a custom esemble model using majority voting machanism, including hard voting and soft voting. We then implemented a hard voting and a soft voting, and compared them. Finally, we evaluate both of their performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Custom Esemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "class EnsembleModel():\n",
    "\n",
    "    def __init__(self, voting):\n",
    "        self.voting = voting\n",
    "        \n",
    "\n",
    "    def predict(self, predictions, weights=[]):\n",
    "        # Stack the predictions into a single array\n",
    "        predictions_stack = np.stack(predictions)  # stack prediction of base classifiers; shape: (num_of_base_models, num_of_test_instances)\n",
    "        \n",
    "        # print(predictions.shape)\n",
    "        if (self.voting == \"soft\"):\n",
    "            # Soft Voting\n",
    "            # Compute the weighted average of the predictions along the first axis (i.e., across each column)\n",
    "            if (weights == []):\n",
    "                # Default: weights are equal\n",
    "                soft_pred_prob = np.average(predictions_stack, axis=0)\n",
    "            else:\n",
    "                # Use passing weights\n",
    "                soft_pred_prob = np.average(predictions_stack, axis=0, weights=weights)\n",
    "\n",
    "            soft_pred = np.where(soft_pred_prob > 0.5, 1, 0)  # probability to 0/1\n",
    "            return soft_pred\n",
    "        else:\n",
    "            # Hard Voting\n",
    "            # Compute the mode of the predictions along the first axis (i.e., across each column)\n",
    "            mode_pred = mode(predictions_stack, axis=0).mode\n",
    "            mode_pred = np.transpose(mode_pred) \n",
    "            mode_pred = np.squeeze(mode_pred)\n",
    "            # print(mode_pred)\n",
    "            # print(mode_pred.shape)\n",
    "            return mode_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hard Voting VS. Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048,)\n",
      "(6513,)\n",
      "(16281,)\n"
     ]
    }
   ],
   "source": [
    "# prepare target values\n",
    "y_train = y_train_tree\n",
    "y_val = y_val_tree\n",
    "y_test = y_test_tree\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/nxhg4vsx36x27z5gtvc6ylk00000gn/T/ipykernel_67776/2289312344.py:29: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_pred = mode(predictions_stack, axis=0).mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score: 0.7580\n",
      "Validation ROC_AUC score: 0.7597\n"
     ]
    }
   ],
   "source": [
    "predictions_train = [y_pred_tree, y_pred_knn, y_pred_nn, y_pred_nb]  # binary predictions for training data\n",
    "predictions_val = [y_pred_val_tree, y_pred_val_knn, y_pred_val_nn, y_pred_val_nb]  # binary predictions for validation data\n",
    "predictions_test = [y_pred_test_tree, y_pred_test_knn, y_pred_test_nn, y_pred_test_nb]  # binary predictions for testing data\n",
    "\n",
    "e_hard = EnsembleModel(\"hard\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "hard_pred = e_hard.predict(predictions_train)\n",
    "# print(hard_pred)\n",
    "# print(hard_pred.shape)\n",
    "\n",
    "\n",
    "# Make predictions on the validation data\n",
    "hard_pred_val = e_hard.predict(predictions_val)\n",
    "# print(hard_pred_val)\n",
    "# print(hard_pred_val.shape)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,hard_pred))\n",
    "auc = roc_auc_score(y_train, hard_pred)  # ROC score\n",
    "print('Training ROC_AUC score: {:.4f}'.format(auc))\n",
    "\n",
    "auc = roc_auc_score(y_val, hard_pred_val)  # ROC score\n",
    "print('Validation ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score: 0.7843\n",
      "Validation ROC_AUC score: 0.7597\n"
     ]
    }
   ],
   "source": [
    "predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "predictions_test = [y_pred_test_tree_proba, y_pred_test_knn_proba, y_pred_test_nn_proba, y_pred_test_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "# default weights = [1, 1, 1, 1]\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred = e_soft.predict(predictions_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val = e_soft.predict(predictions_val)\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "auc = roc_auc_score(y_train, soft_pred)  # ROC score\n",
    "print('Training ROC_AUC score: {:.4f}'.format(auc))\n",
    "auc = roc_auc_score(y_val, hard_pred_val)  # ROC score\n",
    "print('Validation ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation ROC_AUC score of them are the same (i.e., 0.7597), but the training ROC_AUC score (i.e., 0.7843) is higher on the soft voting model (i.e., 0.7580). So it is considered better than the hard voting model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluation\n",
    "We wanted to know how them perform on unseen data, so we evaluated both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/nxhg4vsx36x27z5gtvc6ylk00000gn/T/ipykernel_67776/2289312344.py:29: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_pred = mode(predictions_stack, axis=0).mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91     12435\n",
      "           1       0.74      0.56      0.64      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.81      0.75      0.77     16281\n",
      "weighted avg       0.84      0.85      0.84     16281\n",
      "\n",
      "Hard voting ROC_AUC score: 0.7509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     12435\n",
      "           1       0.71      0.62      0.66      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.80      0.77      0.78     16281\n",
      "weighted avg       0.84      0.85      0.85     16281\n",
      "\n",
      "Soft voting ROC_AUC score: 0.7720\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "predictions_test = [y_pred_test_tree, y_pred_test_knn, y_pred_test_nn, y_pred_test_nb]  # binary predictions for testing data\n",
    "hard_pred_test = e_hard.predict(predictions_test)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions_test = [y_pred_test_tree_proba, y_pred_test_knn_proba, y_pred_test_nn_proba, y_pred_test_nb_proba]  # probability predictions for validation data\n",
    "soft_pred_test = e_soft.predict(predictions_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, hard_pred_test))\n",
    "auc = roc_auc_score(y_test, hard_pred_test)  # ROC score\n",
    "print('Hard voting ROC_AUC score: {:.4f}'.format(auc))\n",
    "\n",
    "print(classification_report(y_test,soft_pred_test))\n",
    "auc = roc_auc_score(y_test, soft_pred_test)  # ROC score\n",
    "print('Soft voting ROC_AUC score: {:.4f}'.format(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft voting also perform better on the unseen data than hard voting, so we now focus on the soft voting model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyper-parameter Tuning\n",
    "This section displays how the tuning was done. Since we are using a soft voting model, we use the weights of the resulting probability of different base models as the parameters to be tuned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Test domination of different models\n",
    "By assigning high weights to one of the models and low weights to other models, we can see which one leads to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score 1 (dt): 0.7811\n",
      "Training ROC_AUC score 2 (knn): 0.7741\n",
      "Training ROC_AUC score 3 (nn): 0.7790\n",
      "Training ROC_AUC score 4 (bnb): 0.7695\n",
      "Validation ROC_AUC score 1 (dt): 0.7889\n",
      "Validation ROC_AUC score 2 (knn): 0.6302\n",
      "Validation ROC_AUC score 3 (nn): 0.7822\n",
      "Validation ROC_AUC score 4 (bnb): 0.7736\n"
     ]
    }
   ],
   "source": [
    "predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "predictions_test = [y_pred_test_tree_proba, y_pred_test_knn_proba, y_pred_test_nn_proba, y_pred_test_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "weights1 = [0.7, 0.1, 0.1, 0.1]  # decision tree dominate\n",
    "weights2 = [0.1, 0.7, 0.1, 0.1]  # knn deminate\n",
    "weights3 = [0.1, 0.1, 0.7, 0.1]  # neutral network dominate\n",
    "weights4 = [0.1, 0.1, 0.1, 0.7]  # Bernoulli NB\n",
    "\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred_1 = e_soft.predict(predictions_train, weights1)\n",
    "soft_pred_2 = e_soft.predict(predictions_train, weights2)\n",
    "soft_pred_3 = e_soft.predict(predictions_train, weights3)\n",
    "soft_pred_4 = e_soft.predict(predictions_train, weights4)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val_1 = e_soft.predict(predictions_val, weights1)\n",
    "soft_pred_val_2 = e_soft.predict(predictions_val, weights2)\n",
    "soft_pred_val_3 = e_soft.predict(predictions_val, weights3)\n",
    "soft_pred_val_4 = e_soft.predict(predictions_val, weights4)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "print('Training ROC_AUC score 1 (dt): {:.4f}'.format(roc_auc_score(y_train, soft_pred_1)))\n",
    "print('Training ROC_AUC score 2 (knn): {:.4f}'.format(roc_auc_score(y_train, soft_pred_2)))\n",
    "print('Training ROC_AUC score 3 (nn): {:.4f}'.format(roc_auc_score(y_train, soft_pred_3)))\n",
    "print('Training ROC_AUC score 4 (bnb): {:.4f}'.format(roc_auc_score(y_train, soft_pred_4)))\n",
    "\n",
    "print('Validation ROC_AUC score 1 (dt): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_1)))\n",
    "print('Validation ROC_AUC score 2 (knn): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_2)))\n",
    "print('Validation ROC_AUC score 3 (nn): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_3)))\n",
    "print('Validation ROC_AUC score 4 (bnb): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree dominate model gave the best result both on the training set and validation set, so it is considered to be the best model.\n",
    "\n",
    "The knn performs worst on the validation set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Attempt improving the preformance\n",
    "Now that we know when the decision tree is dominate, the performance is better. Next, we want to try lifting and decrising its weight, and see if we can further improve."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Increasing weights of decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score 1 (0.7): 0.7811\n",
      "Training ROC_AUC score 2 (0.8): 0.7822\n",
      "Training ROC_AUC score 3 (0.9): 0.7844\n",
      "Training ROC_AUC score 4 (1.0): 0.7852\n",
      "Validation ROC_AUC score 1 (0.7): 0.7889\n",
      "Validation ROC_AUC score 2 (0.8): 0.7897\n",
      "Validation ROC_AUC score 3 (0.9): 0.7928\n",
      "Validation ROC_AUC score 4 (1.0): 0.7921\n"
     ]
    }
   ],
   "source": [
    "# predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "# predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "weights1 = [0.7, 0.1, 0.1, 0.1]  # decision tree dominate\n",
    "weights2 = [0.8, 0.067, 0.067, 0.066]  # decision tree dominate\n",
    "weights3 = [0.9, 0.034, 0.034, 0.034]  # decision tree dominate\n",
    "weights4 = [1, 0, 0, 0]  # decision tree dominate\n",
    "\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred_1 = e_soft.predict(predictions_train, weights1)\n",
    "soft_pred_2 = e_soft.predict(predictions_train, weights2)\n",
    "soft_pred_3 = e_soft.predict(predictions_train, weights3)\n",
    "soft_pred_4 = e_soft.predict(predictions_train, weights4)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val_1 = e_soft.predict(predictions_val, weights1)\n",
    "soft_pred_val_2 = e_soft.predict(predictions_val, weights2)\n",
    "soft_pred_val_3 = e_soft.predict(predictions_val, weights3)\n",
    "soft_pred_val_4 = e_soft.predict(predictions_val, weights4)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "print('Training ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_train, soft_pred_1)))\n",
    "print('Training ROC_AUC score 2 (0.8): {:.4f}'.format(roc_auc_score(y_train, soft_pred_2)))\n",
    "print('Training ROC_AUC score 3 (0.9): {:.4f}'.format(roc_auc_score(y_train, soft_pred_3)))\n",
    "print('Training ROC_AUC score 4 (1.0): {:.4f}'.format(roc_auc_score(y_train, soft_pred_4)))\n",
    "\n",
    "print('Validation ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_1)))\n",
    "print('Validation ROC_AUC score 2 (0.8): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_2)))\n",
    "print('Validation ROC_AUC score 3 (0.9): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_3)))\n",
    "print('Validation ROC_AUC score 4 (1.0): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We foudout that increasing the weights of the decision tree model help to improve the preformance. Comparing validation scores, we choose the third weights, [0.9, 0.034, 0.034, 0.034], as a candidate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Decreasing weights of decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC_AUC score 1 (0.7): 0.7811\n",
      "Training ROC_AUC score 2 (0.6): 0.7855\n",
      "Training ROC_AUC score 3 (0.5): 0.7849\n",
      "Training ROC_AUC score 4 (0.4): 0.7834\n",
      "Validation ROC_AUC score 1 (0.7): 0.7889\n",
      "Validation ROC_AUC score 2 (0.6): 0.7930\n",
      "Validation ROC_AUC score 3 (0.5): 0.7931\n",
      "Validation ROC_AUC score 4 (0.4): 0.7860\n"
     ]
    }
   ],
   "source": [
    "# predictions_train = [y_pred_tree_proba, y_pred_knn_proba, y_pred_nn_proba, y_pred_nb_proba]  # probability predictions for training data\n",
    "# predictions_val = [y_pred_val_tree_proba, y_pred_val_knn_proba, y_pred_val_nn_proba, y_pred_val_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "weights1 = [0.7, 0.1, 0.1, 0.1]  # decision tree dominate\n",
    "weights2 = [0.6, 0.013, 0.013, 0.013]  # decision tree dominate\n",
    "weights3 = [0.5, 0.017, 0.017, 0.017]  # decision tree dominate\n",
    "weights4 = [0.4, 0.2, 0.2, 0.2 ]  # decision tree dominate\n",
    "\n",
    "e_soft = EnsembleModel(\"soft\")\n",
    "\n",
    "# Make predictions on the training data\n",
    "soft_pred_1 = e_soft.predict(predictions_train, weights1)\n",
    "soft_pred_2 = e_soft.predict(predictions_train, weights2)\n",
    "soft_pred_3 = e_soft.predict(predictions_train, weights3)\n",
    "soft_pred_4 = e_soft.predict(predictions_train, weights4)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "soft_pred_val_1 = e_soft.predict(predictions_val, weights1)\n",
    "soft_pred_val_2 = e_soft.predict(predictions_val, weights2)\n",
    "soft_pred_val_3 = e_soft.predict(predictions_val, weights3)\n",
    "soft_pred_val_4 = e_soft.predict(predictions_val, weights4)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "# print(classification_report(y_test,soft_pred))\n",
    "print('Training ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_train, soft_pred_1)))\n",
    "print('Training ROC_AUC score 2 (0.6): {:.4f}'.format(roc_auc_score(y_train, soft_pred_2)))\n",
    "print('Training ROC_AUC score 3 (0.5): {:.4f}'.format(roc_auc_score(y_train, soft_pred_3)))\n",
    "print('Training ROC_AUC score 4 (0.4): {:.4f}'.format(roc_auc_score(y_train, soft_pred_4)))\n",
    "\n",
    "print('Validation ROC_AUC score 1 (0.7): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_1)))\n",
    "print('Validation ROC_AUC score 2 (0.6): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_2)))\n",
    "print('Validation ROC_AUC score 3 (0.5): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_3)))\n",
    "print('Validation ROC_AUC score 4 (0.4): {:.4f}'.format(roc_auc_score(y_val, soft_pred_val_4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best validation score is given by the third weight. However, we notice the second weights perform well on both the training set and the validation set. So the second weights, [0.6, 0.013, 0.013, 0.013], is considered the best weights. \n",
    "\n",
    "Compared the validation score with the model with weights (i.e., [0.9, 0.034, 0.034, 0.034]) from the previous section (0.7928), the model with decreased weights is better (0.7930). So, weights = [0.6, 0.013, 0.013, 0.013] would be the best parameter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the best model has been chosen. It is a soft voting classifier with weights [0.6, 0.013, 0.013, 0.013]. We noe evaluate its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 0s 715us/step\n",
      "Total execution time: 11.4012 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90     12435\n",
      "           1       0.71      0.63      0.67      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.80      0.78      0.79     16281\n",
      "weighted avg       0.85      0.85      0.85     16281\n",
      "\n",
      "Soft voting ROC_AUC score: 0.7768\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[11434  1001]\n",
      " [ 1407  2439]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Mark the start time\n",
    "time_start = time.time()  \n",
    "\n",
    "# Make predictions using dt\n",
    "y_pred_test_tree_proba = decision_tree.predict_proba(x_test_tree)[:, 1]  # probability of \">50k\"\n",
    "# Make predictions using knn\n",
    "y_pred_test_knn_proba = knn_model.predict_proba(x_test_knn)[:, 1]  # probability of \">50k\"\n",
    "# Make predictions using nn\n",
    "y_pred_test_nn_proba = nn_model.predict(x_test_nn)  # probability of \">50k\"\n",
    "y_pred_test_nn_proba = np.squeeze(y_pred_test_nn_proba)  # to 1-d array\n",
    "# Make predictions using nb\n",
    "y_pred_test_nb_proba = nb_model.predict_proba(x_test_nb)[:, 1]  # probability of \">50k\"\n",
    "\n",
    "predictions_test = [y_pred_test_tree_proba, y_pred_test_knn_proba, y_pred_test_nn_proba, y_pred_test_nb_proba]  # probability predictions for validation data\n",
    "\n",
    "best_weights = [0.6, 0.013, 0.013, 0.013]  # decision tree dominate\n",
    "\n",
    "model_ensemble = EnsembleModel(\"soft\")  # soft voting model\n",
    "\n",
    "# Make predictions on the testing data\n",
    "soft_pred = model_ensemble.predict(predictions_test, best_weights)\n",
    "\n",
    "# Mark the end time\n",
    "time_end = time.time()  # mark the end time\n",
    "total_execution_time = time_end - time_start\n",
    "print('Total execution time: {:.4f} s'.format(total_execution_time))\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test,soft_pred))\n",
    "auc = roc_auc_score(y_test, soft_pred)  # ROC score\n",
    "print('Soft voting ROC_AUC score: {:.4f}'.format(auc))\n",
    "\n",
    "#plotting roc curve\n",
    "fpr, tpr, _ = roc_curve(y_test, soft_pred)\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "#Confusion matrix\n",
    "cm = (confusion_matrix(y_test,soft_pred,))\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "#confusion matrix plot\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
