{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instance Based Learning\n",
    "\n",
    "In this notebook you will learn how to implement the k-Nearest Neighbors (kNN) algorithm in Python and learn how to\n",
    "use kNN and SVN algorithms in scikit-learn.\n",
    "\n",
    "## 1. The Dataset\n",
    "\n",
    "This notebook will work with the [Adult dataset](https://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "In the following table are the properties of this dataset.\n",
    "\n",
    "|Property|Value|\n",
    "|--|--|\n",
    "|Classes|2|\n",
    "|Samples per class|(not yet fill)|\n",
    "|Samples total|32561|\n",
    "|Dimensionality|(not yet fill)|\n",
    "|Features|positive, natural and real (dont know what this mean)|\n",
    "\n",
    "Each example contains a class identifier and 14 attributes representing the outcome of the analysis performed on the\n",
    "adult samples.\n",
    "\n",
    "We will download this dataset directly from the UCI repository using Pandas. Note that this dataset does not have a\n",
    "header which means that we need to provide the column names manually. This header comes from reading the content of this\n",
    "[file](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names)\n",
    "(you can open this file with a text editor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "\n",
    "names = ['age', # label\n",
    "         'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship',\n",
    "         'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'target']\n",
    "\n",
    "df = pd.read_csv(dataset_url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first have a look at the content of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's also have a look at some statistics of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    32561.000000  \n",
       "mean        40.437456  \n",
       "std         12.347429  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Preprocessing the Dataset\n",
    "\n",
    "This dataset will require some preprocessing. First, since we would like to test how any of the learning algorithms\n",
    "used later perform on unseen data. We split the dataset into a training set and a test set.\n",
    "\n",
    "To do this we first randomize the data. We do this in order to make sure to select an unbiased set of examples\n",
    "for the test set. Notice that in this case the training is sorted based on the target `class`, which makes the\n",
    "initial randomization necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22454</th>\n",
       "      <td>67</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>286372</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27096</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>114765</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26303</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>259846</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>3471</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28214</th>\n",
       "      <td>37</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>353298</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>63</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>97855</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt   education  education-num  \\\n",
       "22454   67   Self-emp-not-inc  286372   Bachelors             13   \n",
       "27096   35            Private  114765   Bachelors             13   \n",
       "26303   37            Private  259846   Assoc-voc             11   \n",
       "28214   37   Self-emp-not-inc  353298     HS-grad              9   \n",
       "2324    63        Federal-gov   97855     Masters             14   \n",
       "\n",
       "            marital-status         occupation    relationship    race  \\\n",
       "22454   Married-civ-spouse   Transport-moving         Husband   White   \n",
       "27096             Divorced              Sales   Not-in-family   White   \n",
       "26303   Married-civ-spouse       Adm-clerical         Husband   White   \n",
       "28214   Married-civ-spouse              Sales         Husband   White   \n",
       "2324    Married-civ-spouse    Exec-managerial         Husband   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "22454     Male             0             0              40   United-States   \n",
       "27096   Female             0             0              40   United-States   \n",
       "26303     Male          3471             0              40   United-States   \n",
       "28214     Male         99999             0              50   United-States   \n",
       "2324      Male             0             0              50   United-States   \n",
       "\n",
       "       target  \n",
       "22454   <=50K  \n",
       "27096   <=50K  \n",
       "26303   <=50K  \n",
       "28214    >50K  \n",
       "2324     >50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Splitting Dataframe into integers and strings\n",
    "(adapted from: https://www.kaggle.com/code/mukeshgurpude/adult-income-dataset-with-knn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str = df.select_dtypes(include='object')\n",
    "df_int = df.select_dtypes(exclude='object')\n",
    "df_str.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str = pd.get_dummies(df_str)\n",
    "df_str.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Dividing Train and Test Datasets\n",
    "We now separate the target `class` from the rest of the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# this sets the numpy to print numbers with float precision (this setting affects only the prints not the actual values)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "ys, xs = np.split(df.values, [1], axis=1)\n",
    "ys = ys.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And select 80% of the dataset for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape:\t (26048, 14)\n",
      "test set shape:\t\t (6513, 14)\n"
     ]
    }
   ],
   "source": [
    "n_train = len(xs) * 80 // 100\n",
    "xs_train, xs_test = np.split(xs, [n_train], axis=0)\n",
    "ys_train, ys_test = np.split(ys, [n_train], axis=0)\n",
    "\n",
    "print('training set shape:\\t', xs_train.shape)\n",
    "print('test set shape:\\t\\t', xs_test.shape)\n",
    "\n",
    "#output would look like this:\n",
    "#training set shape:\t (26048, 14)\n",
    "#test set shape:\t\t (6513, 14)\n",
    "#which means (number of instances, 14 attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we note that attribute values span across various ranges: Some attributes have a much wider range than others.\n",
    "Since the learning algorithms that we will be using later are based on some form of distance function,\n",
    "this variance in the ranges of the attributes may bias the learning algorithm towards examples that look closer in\n",
    "dimensions with a wider range because those attributes will dominate the distance functions.\n",
    "In order to mitigate this bias we perform a normalization across the features. In this case we will perform a\n",
    "standardization (aka Z-score):\n",
    "\n",
    "\\begin{equation}\n",
    "z = \\frac{x-\\mu}{\\sigma}\n",
    "\\end{equation}\n",
    "\n",
    "Any other normalization that achieves a similar result is also fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mu \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmean(xs_train, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m sigma \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstd(xs_train, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m xs_train \u001b[39m=\u001b[39m (xs_train \u001b[39m-\u001b[39m mu)\u001b[39m/\u001b[39msigma\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zohar\\.conda\\envs\\geospatial\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3369\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3370\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 3372\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39;49m_mean(a, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   3373\u001b[0m                       out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zohar\\.conda\\envs\\geospatial\\lib\\site-packages\\numpy\\core\\_methods.py:162\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    160\u001b[0m ret \u001b[39m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims)\n\u001b[0;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m--> 162\u001b[0m     ret \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39;49mtrue_divide(\n\u001b[0;32m    163\u001b[0m             ret, rcount, out\u001b[39m=\u001b[39;49mret, casting\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39munsafe\u001b[39;49m\u001b[39m'\u001b[39;49m, subok\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    164\u001b[0m     \u001b[39mif\u001b[39;00m is_float16_result \u001b[39mand\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m         ret \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype(ret)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "mu = np.mean(xs_train, axis=0)\n",
    "sigma = np.std(xs_train, axis=0)\n",
    "\n",
    "xs_train = (xs_train - mu)/sigma\n",
    "xs_test = (xs_test - mu)/sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that the normalization should be computed on the training set and not on the original dataset. This in order to\n",
    "better simulate unseen data. The normalization, together with any preprocessing step that involves statistics over\n",
    "the dataset, should also be considered as belonging to the hyper-parameters of the learning algorithm.\n",
    "\n",
    "After having performed the normalization, if we now compute the mean of the preprocessed training set, we should see\n",
    "that now this mean vector contains only zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(xs_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we have properly sampled the dataset, we should get a mean vector for the test set that contains close to zero\n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(xs_test, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Nearest Neighbor Algorithm\n",
    "\n",
    "We will now implement the Nearest Neighbor (NN) algorithm in Python from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "\n",
    "    def __init__(self, distance):\n",
    "        self.training_examples = []\n",
    "        self.distance = distance\n",
    "\n",
    "    def add_example(self, x, y):\n",
    "        \"\"\"\n",
    "        Add one example to the list of training examples.\n",
    "        :param x: The vector of feature values\n",
    "        :param y: The label associated to this example\n",
    "        \"\"\"\n",
    "        self.training_examples.append((x, y))\n",
    "\n",
    "    def add_examples(self, xs, ys):\n",
    "        \"\"\"\n",
    "        Add a list of examples to the list of training examples.\n",
    "        :param xs: A list of vectors of fature values\n",
    "        :param ys: A list of labels associated to the examples\n",
    "        \"\"\"\n",
    "        for x, y in zip(xs, ys):\n",
    "            self.add_example(x, y)\n",
    "\n",
    "    def closest_training_example(self, x_q):\n",
    "        y_closest = None\n",
    "        x_closest = None\n",
    "        min_score = float('inf')\n",
    "        # find closest example\n",
    "        for x, y in self.training_examples:\n",
    "            score = self.distance(x_q, x)\n",
    "            if score < min_score:\n",
    "                min_score = score\n",
    "                x_closest = x\n",
    "                y_closest = y\n",
    "\n",
    "        return x_closest, y_closest\n",
    "\n",
    "    def classify(self, xq):\n",
    "        _, y_hat = self.closest_training_example(xq)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to instantiate this classifier we need to define a distance function. Since we are dealing with continuous\n",
    "features we will define the euclidean distance. You are invited to develop and test another distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(x_1, x_2):\n",
    "    res = 0\n",
    "    for a_1, a_2 in zip(x_1, x_2):\n",
    "        res += (a_1 - a_2) ** 2\n",
    "    res **= 0.5\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The euclidean distance of the points (0, 0) and (1, 1) should be $\\sqrt{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "euclidean_distance([0, 0], [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now instantiate the NN classifier and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nn_clf = NN(euclidean_distance)\n",
    "\n",
    "nn_clf.add_examples(xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To evaluate how this classifier performs on the test set we will measure its accuracy. Note that evaluating the\n",
    "accuracy on the training set is pointless because this will always be 1 by definition. We will now do also this only for\n",
    "instructive purposes.\n",
    "\n",
    "We now define the accuracy measure. Remember that the accuracy is equal to the proportion of examples that the\n",
    "classifier predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(ys, ys_hat):\n",
    "    res = 0\n",
    "    for y, y_hat in zip(ys, ys_hat):\n",
    "        if y == y_hat:\n",
    "            res += 1\n",
    "    res /= len(ys)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now test the classifier on both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ys_train_pred = []\n",
    "for x in xs_train:\n",
    "    y_hat = nn_clf.classify(x)\n",
    "    ys_train_pred.append(y_hat)\n",
    "\n",
    "ys_test_pred = []\n",
    "for x in xs_test:\n",
    "    y_hat = nn_clf.classify(x)\n",
    "    ys_test_pred.append(y_hat)\n",
    "\n",
    "print('Train accuracy of NN', accuracy(ys_train, ys_train_pred))\n",
    "print('Test accuracy of NN', accuracy(ys_test, ys_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now compare the test result of this classifier to a random classifier. Is this NN classifier any better?\n",
    "Remember that a random classifier would correctly predict the class one third of the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ys_test_pred_random = np.random.randint(1, 4, len(ys_test))\n",
    "print('Test accuracy of a random classifier', accuracy(ys_test, ys_test_pred_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's have a look at the result of a random classifier by repeating this experiment many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "accuracies = []\n",
    "for _ in range(10000):\n",
    "    ys_test_pred_random = np.random.randint(1, 4, len(ys_test))\n",
    "    accuracies.append(accuracy(ys_test, ys_test_pred_random))\n",
    "\n",
    "plt.hist(accuracies)\n",
    "plt.show()\n",
    "\n",
    "print('Expected accuracy of a random classifier', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Does this accuracy make sense? Is this accuracy similar to the one you had predicted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The k-Nearest Neighbor Algorithm\n",
    "\n",
    "We will now extend the NN algorithm to develop the k-Nearest Neighbor (kNN) algorithm.\n",
    "By extending the NN algorithm we avoid repeating the training code. This is in fact the same.\n",
    "In the classification method, in order to avoid the sorting of\n",
    "all the examples after having measured their score, we will make use of priority queues, which allow us to keep track\n",
    "only of the first $k$-nearest examples, making the code more efficient. You are free to implement the version where\n",
    "first all the examples are scored, then sorted and selected. These two versions, if correctly implemented,\n",
    "should produce to the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from heapq import heappush, heappushpop\n",
    "\n",
    "class KNN(NN):\n",
    "\n",
    "    def __init__(self, distance):\n",
    "        super().__init__(distance)\n",
    "\n",
    "    def closest_training_examples(self, x_q, k=1):\n",
    "        k_nearest = []\n",
    "\n",
    "        # initialize an heap with k elements\n",
    "        for x, y  in self.training_examples[:k]:\n",
    "            score = self.distance(x_q, x)\n",
    "            heappush(k_nearest, (-score, (x, y)))\n",
    "\n",
    "        # find the k-nearest example\n",
    "        for x, y in self.training_examples[k:]:\n",
    "            score = self.distance(x_q, x)\n",
    "            heappushpop(k_nearest, (-score, (x, y)))\n",
    "\n",
    "        # we no longer need to keep the score\n",
    "        res = [(x, y) for _, (x, y) in k_nearest]\n",
    "        return res\n",
    "\n",
    "    def classify(self, x_q, k = 1):\n",
    "        # find the k closest\n",
    "        k_nearest_xs, k_nearest_ys = zip(*self.closest_training_examples(x_q, k))\n",
    "        # return the mode\n",
    "        return mode(k_nearest_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now train and test this algorithm in the same way we did for the NN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_clf = KNN(euclidean_distance)\n",
    "\n",
    "knn_clf.add_examples(xs_train, ys_train)\n",
    "\n",
    "ys_train_pred = []\n",
    "for x in xs_train:\n",
    "    y_hat = knn_clf.classify(x)\n",
    "    ys_train_pred.append(y_hat)\n",
    "\n",
    "ys_test_pred = []\n",
    "for x in xs_test:\n",
    "    y_hat = knn_clf.classify(x)\n",
    "    ys_test_pred.append(y_hat)\n",
    "\n",
    "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
    "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nothing has changed with respect to the NN algorithm because we have implicitly used $k=1$. Let's now try $k=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ys_train_pred = []\n",
    "for x in xs_train:\n",
    "    y_hat = knn_clf.classify(x, 5)\n",
    "    ys_train_pred.append(y_hat)\n",
    "\n",
    "ys_test_pred = []\n",
    "for x in xs_test:\n",
    "    y_hat = knn_clf.classify(x, 5)\n",
    "    ys_test_pred.append(y_hat)\n",
    "\n",
    "\n",
    "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
    "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems that considering more points did not help. Note that this time the training accuracy has changed. Can you\n",
    "explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## kNN in Scikit-Learn\n",
    "\n",
    "We will now learn how to use the kNN implementation of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_clf.fit(xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now evaluate the result of this classifier. Here, we should not see any\n",
    "difference with respect to the results obtained above with our implementation of the kNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ys_test_pred = knn_clf.predict(xs_test)\n",
    "\n",
    "print('Test accuracy of kNN', accuracy_score(ys_test, ys_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now try the cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=1, metric='cosine')\n",
    "\n",
    "knn_clf.fit(xs_train, ys_train)\n",
    "\n",
    "ys_test_pred = knn_clf.predict(xs_test)\n",
    "\n",
    "print('Test accuracy of kNN', accuracy_score(ys_test, ys_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Try other $n$ values. Can you find a better one? The danger of doing this hyper-parameter exploration using the test set is\n",
    "that we may overfit these hyper-parameters on the test set.\n",
    "To avoid this, it is better to find the best hyper-parameter values via a validation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To find these hyper-parameter values we can exploit the grid search of scikit-learn. This will perform a k-fold\n",
    "cross-validation on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\n",
    "    'weights': [\"uniform\", \"distance\"],\n",
    "    'n_neighbors': range(1, 11),\n",
    "    'metric':['euclidean', 'manhattan', 'cosine']}]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=2)\n",
    "grid_search.fit(xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now see what are the best hyper-parameter values found by the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now try this hyper-parameters on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(metric='cosine', n_neighbors=4, weights='distance')\n",
    "\n",
    "knn_clf.fit(xs_train, ys_train)\n",
    "\n",
    "ys_train_pred = knn_clf.predict(xs_train)\n",
    "ys_test_pred = knn_clf.predict(xs_test)\n",
    "\n",
    "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
    "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The accuracy measured on the test set is now a better estimate of the accuracy we would expect on unseen examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Here I will introduce you how to use the Support Vector Machine (SVM) implementation of scikit-learn.\n",
    "\n",
    "Note how we are setting the $C$ hyper-parameter of SVM. $C$ controls the trade-off between having a small and strict\n",
    "margin and a wider and loose margin. Following we will set $C$ to infinity which makes the margin infinitely strict.\n",
    "This means that based on the dataset, the fitting of the SVM may fail if the training algorithm fails to separate all\n",
    "the training examples perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now train this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svm_clf.fit(xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training went well, which means that the SVM training algorithm managed to perfectly fit the training examples.\n",
    "We can now verify this on the training set. We will also test the performance of this classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ys_train_pred = svm_clf.predict(xs_train)\n",
    "ys_test_pred = svm_clf.predict(xs_test)\n",
    "\n",
    "print('Train accuracy of SVM', accuracy(ys_train, ys_train_pred))\n",
    "print('Test accuracy of SVM', accuracy(ys_test, ys_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "How would you find the best hyper-parameter C value? Try re-implement the code used to validate the kNN\n",
    "classifier above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "679b5fba4bae358bb6b34f10e985cbbc21cdf1dc3c02317452068964773177e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
